{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the training set\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes have the following meaning:\n",
    "\n",
    "- **Survived**: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.\n",
    "- **Pclass**: passenger class.\n",
    "- __Name, Sex, Age__: self-explanatory\n",
    "- __SibSp__: how many siblings & spouses of the passenger aboard the Titanic.\n",
    "- __Parch__: how many children & parents of the passenger aboard the Titanic.\n",
    "- __Ticket__: ticket id\n",
    "- __Fare__: price paid (in pounds)\n",
    "- __Cabin__: passenger's cabin number\n",
    "- __Embarked__: where the passenger embarked the Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['Survived'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Age, Cabin and Embarked__ have missing values, we need to take care of them.\n",
    "\n",
    "We can use median strategy imputer on age and for embarked the most frequent one. But Cabin has so much missing data over 77%, so it's better to drop it.\n",
    "\n",
    "Let's understand the categorical values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347082      7\n",
       "CA. 2343    7\n",
       "1601        7\n",
       "CA 2144     6\n",
       "347088      6\n",
       "           ..\n",
       "A/5 3540    1\n",
       "2686        1\n",
       "113028      1\n",
       "368323      1\n",
       "2926        1\n",
       "Name: Ticket, Length: 681, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Ticket'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So many categories!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B96 B98        4\n",
       "C23 C25 C27    4\n",
       "G6             4\n",
       "F33            3\n",
       "D              3\n",
       "              ..\n",
       "B30            1\n",
       "D49            1\n",
       "C45            1\n",
       "E49            1\n",
       "B38            1\n",
       "Name: Cabin, Length: 147, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Cabin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, so many categories!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Port of Embarkation__: C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    491\n",
       "1    216\n",
       "2    184\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Pclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    608\n",
       "1    209\n",
       "2     28\n",
       "4     18\n",
       "3     16\n",
       "8      7\n",
       "5      5\n",
       "Name: SibSp, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['SibSp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    678\n",
       "1    118\n",
       "2     80\n",
       "5      5\n",
       "3      5\n",
       "4      4\n",
       "6      1\n",
       "Name: Parch, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Parch'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ticket Class__: 1 = 1st, 2 = 2nd, 3 = 3rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __PassengerId__ does tell anything interesting.\n",
    "- __Survived__'s mean is 0.38 (approx.) meaning that only 38% survived!\n",
    "- __Pclass__'s mean is around 2.3 meaning majority of the people were middle of lower class. But by looking at the distribution of Pclass we found that 55% of the people belong to lower class while upper and middle class are close in numbers.\n",
    "- __Age__'s mean is around 29 with std deviation around 14.5, min is 0.4 and max is 80. median is 28 and 25% of the people are less than 20 years old, and 75% of the people are less than 38 years old. (We should probably plot a histogram also).\n",
    "- __SibSp__ 52% have siblings/ spouse. max is 8. Could be converted into feature telling if passenger have sibling/spouse or not because 68% of the people don't have them in the ship.\n",
    "- __Parch__ 38% have parents/children. max is 6. Could be converted into feature telling if passenger have sibling/spouse or not because 76% of the people don't have them in the ship.\n",
    "- __Fare__ mean is 32 (approx.). 75% of the people pay 31 or less while max is 512! (A Histogram would be great representation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Data through visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIcAAANeCAYAAACI527yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzde7xkZX3n+89XQEBAG0R2msuxdSReYkfEljAHdbYQlYsRcl5qNIw0hJzOOeJEYyfaJvMadaITPAkSNcRjRxSMKDIogQHigSBb40xARZGLaGhIB1paWuUiLYo2+Z0/am0pdtdu9qWuuz7v16teVeupZ631e3bVrqfqt571rFQVkiRJkiRJGk+PG3QAkiRJkiRJGhyTQ5IkSZIkSWPM5JAkSZIkSdIYMzkkSZIkSZI0xkwOSZIkSZIkjTGTQ5IkSZIkSWPM5JAkSZIkSUMuyVSS3x10HFqaTA5pyWo+PO9NsuugY5EkjYYkG5P8JMnWttv+g45LkjTcZvQfdyf5eJI9Bx2XNFcmh7QkJVkBvBgo4FUDDUaSNGp+o6r2bLvdNZ+Vk+zUq8AkSUPtN6pqT+BQ4IXAf57Pykl27klU0hyYHNJSdRJwDXAOsHq6MMmTk/yPJD9K8tUk70ny5bbnn5XkyiT3JPlOktf2P3RJ0jBJ8rgkFyb5XpL7mpGpz257/pNJzkry+SQ/Bl6cZLck709yZ3ME+a+T7DbAZkiS+qSqvgv8PfDcJKckuSXJA0luT/J70/WSTCbZlOTtSb4HfLwpPz7J9c1vltuSHN22+acm+Z/N9q5Ism9/W6elyuSQlqqTgPOa2yuSTDTlZwE/Bn6JVtKoPXG0B3Al8ClgP+D1wF8n+ZU+xi1JGk6XAgfT6j9uAv52xvO/Dbwb2Av4J+AvgKcBv9qstwL4kz7FKkkaoCQHAccC3wC2AK8EngicApyZ5NC26r8E7AM8FViT5DDgE8AfAcuAlwAb2+r/drOd/YDHA3/Yy7ZofKSqBh2D1FVJXgRcDSyvqh8k+TbwEeCDwE+B51bVd5q67wEmq+pFSX4LeFNVvbhtWx8B7qqqd/e9IZKkvkuyEdgX2NYUTVXVCTPq7At8H9izqn6c5JPAz6rqd5rnHwc8CDyzqv61KXsx8LGqOrg/LZEk9dOM/uN+4DJgbVX9ZEa9vwOurqoPJJkErgCeWFU/bZ7/CPBgVf1Bh31MAf9QVe9plt8IvKqqjp5ZV5ovz2nUUrQauKKqftAsf6op+zSt9/ydbXXbHz8V+LUk97WV7cz2R4clSUvbCVX1D9MLzRxCfwa8mtYX/39rntqX1mhUeHR/8kvArsA3k/xiM70MWJI0FB7VfwAkOQZ4J/DLtM7ceQJwY1uV708nhhoHAZfvYB/fa3v8IOCk1+oKk0NaUpLsDrwW2Kk5bxdaX9CXARO0MvkHAv/cPHdQ2+p3Al+sqpf1KVxJ0mg4idbpAUcC/wo8mdbIofaET/tQ7LuBn9EaOXR3v4KUJA2X5qrJn6XVj1xcVT9vRg7N1n9A6zfJv+tTiNIvOOeQlpoTgIeB5wCHNLdnA/9I60P5c8C7kjwhybOasmmXAr+c5A1JdmluL2yfdFSSNJb2Ah4CfkjriO97d1S5qh4GPgr8ZZKnpOXAJC/vfaiSpCHyeFoHqr8PbGtGET1WX3A2cEqSo5oLIhzQ/G6ResrkkJaa1cDHq+qOqvre9A34K+BE4E3Ak2gNx/xbWqeaPQRQVQ/Q+rB+HXBXU+d9tD7QJUnj6+O0+oW7gJuB/zWHddbSGmX0FVpzT1xBa2JqSdKYaH5f/D5wAXAvrcmkL3mMdb5CM3E1rf7ji7Smv5B6ygmpNdaSvA/4papa/ZiVJUmSJElaghw5pLGS5FlJfrUZ4n8YcCpw0aDjkiRJkiRpUJyQWuNmL1qnku0PbAHOAC4eaESSJEmSJA2Qp5VJkiRJkiSNMU8rkyRJkiRJGmNDeVrZvvvuWytWrJhz/R//+MfssccevQtonoYpHmOZ3TDFM0yxwHDFs1Riue66635QVU/pckgjKcluwJdoXQlwZ+DCqnpnknOA/0DryhwAJ1fV9UkCfAA4FniwKf/6Y+1nvn3JtGF6z3WbbRtNtm009aJt9iX9N459ibEPhrEPxqjG3pPfJVU1dLcXvOAFNR9XX331vOr32jDFYyyzG6Z4himWquGKZ6nEAnythuDzdRhuQIA9m8e7ANcChwPnAK/uUP9Y4O+b9Q4Hrp3Lfubbl0wbpvdct9m20WTbRlMv2mZfsl3/8Ezg+rbbj4C3APsAVwK3Nvd71yP9zweBDcANwKGPtY9x7EuMfTCMfTBGNfZe/C7xtDJJUl81/dLWZnGX5rajCfCOBz7RrHcNsCzJ8l7HKUkablX1nao6pKoOAV5Aa3TpRcA64KqqOhi4qlkGOAY4uLmtAT7c/6glaTgN5WllkqSlLclOwHXAM4CzquraJP838N4k/4Xmy3xVPQQcANzZtvqmpmxzh+2uofWFn4mJCaampuYd29atWxe03iiwbaPJto2mpdy2IXUUcFtV/WuS44HJpvxcYAp4O20HG4BrkixLsryqtutPJGncmBySJPVdVT0MHJJkGXBRkucC7wC+BzweWE/ri/x/pXUawHabmGW765t1WbVqVU1OTs47tqmpKRay3iiwbaPJto2mpdy2IfU64NPN44nphE9VbU6yX1M+p4MN436gwdgHw9gHY1Rj70XcJockSQNTVfclmQKOrqq/aIofSvJx4A+b5U3AQW2rHQjc1b8oJUnDLMnjgVfROsiww6odyrY72DDuBxqMfTCMfTBGNfZexO2cQ5KkvkrylGbEEEl2B34d+Pb0PELN1clOAG5qVrkEOCkthwP3ewqAJKnNMcDXq+ruZvnutj5lObClKfdggyTNwuSQJKnflgNXJ7kB+CpwZVVdCpyX5EbgRmBf4D1N/cuB22ldXeZvgDf2P2RJ0hB7PY+cUgatgwqrm8ergYvbyj3YIEkdeFqZJKmvquoG4Pkdyo+cpX4Bp/U6LknS6EnyBOBlwO+1FZ8OXJDkVOAO4DVN+eXAsbQONjwInNLHUCVpqJkckiRJkjSSqupB4Mkzyn5I6+plM+t6sEGSZuFpZZIkSZIkSWPMkUNLwIp1l21XtvH04wYQiSSNvhu/ez8nz/hc9TNVkjQf9iWSRk1Xk0NJNgIPAA8D26pqVZJ9gM8AK4CNwGur6t5u7leSJEmSJEkL04vTyl5aVYdU1apmeR1wVVUdDFzVLEuSJEmSJGkI9GPOoeOBc5vH5wIn9GGfkiRJkiRJmoNuzzlUwBVJCvhIVa0HJqpqM0BVbU6yX6cVk6wB1gBMTEwwNTU1551u3bp1XvV7rd/xrF25bbuy6f0P099mmGKB4YpnmGKB4YrHWCRJkiSpt7qdHDqiqu5qEkBXJvn2XFdsEknrAVatWlWTk5Nz3unU1BTzqd9r/Y5n5mR3ABtPnBxILDsyTLHAcMUzTLHAcMVjLJIkSZLUW109rayq7mrutwAXAYcBdydZDtDcb+nmPiVJkiRJkrRwXUsOJdkjyV7Tj4GXAzcBlwCrm2qrgYu7tU9JkiRJkiQtTjdPK5sALkoyvd1PVdXnk3wVuCDJqcAdwGu6uE9JkiRJkiQtQteSQ1V1O/C8DuU/BI7q1n4kSZIkSZLUPf24lL0kSZIkSZKGlMkhSZIkSZKkMWZySJIkSZIkaYyZHJIkSZIkSRpjJockSZIkSZLGmMkhSZIkSZKkMWZySJIkSZIkaYztPOgAtDSsWHdZx/KNpx/X50gkSZIkSdJ8OHJIkiRJkiRpjJkckiRJkiRJGmMmhyRJkiRJksaYcw4J6DxnkPMFSeqVJLsBXwJ2pdUXXVhV70zyNOB8YB/g68AbqupnSXYFPgG8APgh8FtVtXEgwUuSJElLjCOHJEmD8BBwZFU9DzgEODrJ4cD7gDOr6mDgXuDUpv6pwL1V9QzgzKaeJGmMJVmW5MIk305yS5J/n2SfJFcmubW537upmyQfTLIhyQ1JDh10/JI0TEwOSZL6rlq2Nou7NLcCjgQubMrPBU5oHh/fLNM8f1SS9ClcSdJw+gDw+ap6FvA84BZgHXBVc5DhqmYZ4Bjg4Oa2Bvhw/8OVpOHlaWWSpIFIshNwHfAM4CzgNuC+qtrWVNkEHNA8PgC4E6CqtiW5H3gy8IMZ21xD60s/ExMTTE1NzTuuid1h7cptjypbyHaG0datW5dMW2aybaPJtmmhkjwReAlwMkBV/Qz4WZLjgcmm2rnAFPB2WgcZPlFVBVzTjDpaXlWb+xy6JA0lk0OSpIGoqoeBQ5IsAy4Cnt2pWnPfaZRQbVdQtR5YD7Bq1aqanJycd1wfOu9izrjx0d3jxhPnv51hNDU1xUL+JqPAto0m26ZFeDrwfeDjSZ5H62DDm4GJ6YRPVW1Osl9T/xcHGRrTByC2Sw6N+4GGUU5sGvtgGHv/9SJuk0OSpIGqqvuSTAGHA8uS7NyMHjoQuKuptgk4CNiUZGfgScA9g4hXkjQUdgYOBf5TVV2b5AM8cgpZJ3M6yAAeaBjlxKaxD4ax918v4nbOIUlS3yV5SjNiiCS7A79Oa66Iq4FXN9VWAxc3jy9plmme/0JzaoAkaTxtAjZV1bXN8oW0kkV3J1kO0Nxvaat/UNv67QcgJGnsmRySJA3CcuDqJDcAXwWurKpLac0L8dYkG2jNKXR2U/9s4MlN+VvZ8dFhSdISV1XfA+5M8sym6CjgWzz6YMLMgwwnNVctOxy43/mGJOkRnlYmSeq7qroBeH6H8tuBwzqU/xR4TR9CkySNjv8EnJfk8cDtwCm0Dn5fkORU4A4e6TsuB44FNgAPNnUlSQ2TQ5IkSZJGTlVdD6zq8NRRHeoWcFrPg5KkEeVpZZIkSZIkSWPM5JAkSZIkSdIYMzkkSZIkSZI0xkwOSZIkSZIkjTGTQ5IkSZIkSWPM5JAkSZIkSdIYMzkkSZIkSZI0xkwOSZIkSZIkjTGTQ5IkSZIkSWPM5JAkSZIkSdIYMzkkSZIkSZI0xkwOSZIkSZIkjTGTQ5IkSZIkSWOs68mhJDsl+UaSS5vlpyW5NsmtST6T5PHd3qckSZIkSZIWphcjh94M3NK2/D7gzKo6GLgXOLUH+5QkSZIkSdICdDU5lORA4Djgo81ygCOBC5sq5wIndHOfkiRJkiRJWridu7y9vwTeBuzVLD8ZuK+qtjXLm4ADOq2YZA2wBmBiYoKpqak573Tr1q3zqt9r/Y5n7cpt25V96LyLAZjY/ZHHACsPeNKctzGfNnRaf+Y2xv112pFhigWGKx5jkSRJkqTe6lpyKMkrgS1VdV2SyeniDlWr0/pVtR5YD7Bq1aqanJzsVK2jqakp5lO/1/odz8nrLpv1ubUrt3HGjY+8zBtPnJzzNmarO58Y2rcx7q/TjgxTLDBc8RiLJEmSJPVWN0cOHQG8KsmxwG7AE2mNJFqWZOdm9NCBwF1d3KckSZIkSZIWoWtzDlXVO6rqwKpaAbwO+EJVnQhcDby6qbYauHiWTUiSJEmSJKnPenG1spneDrw1yQZacxCd3Yd9SpIkSZIkaQ66PSE1AFU1BUw1j28HDuvFfiRJkiRJkrQ4/Rg5JEnSLyQ5KMnVSW5JcnOSNzfl70ry3STXN7dj29Z5R5INSb6T5BWDi16SJElaenoyckiSpB3YBqytqq8n2Qu4LsmVzXNnVtVftFdO8hxac9n9CrA/8A9JfrmqHu5r1JKkoZNkI/AA8DCwrapWJdkH+AywAtgIvLaq7k0S4APAscCDwMlV9fVBxC1Jw8aRQ5KkvqqqzdNfxqvqAeAW4IAdrHI8cH5VPVRV/wJswNOVJUmPeGlVHVJVq5rldcBVVXUwcFWzDHAMcHBzWwN8uO+RStKQcuSQJGlgkqwAng9cCxwBvCnJScDXaI0uupdW4uiattU2MUsyKckaWl/4mZiYYGpqat4xTewOa1due1TZQrYzjLZu3bpk2jKTbRtNtk09cjww2Tw+l9ZcqG9vyj9RVQVck2RZkuVVtXkgUUrSEDE5JEkaiCR7Ap8F3lJVP0ryYeBPgWruzwB+B0iH1avTNqtqPbAeYNWqVTU5OTnvuD503sWcceOju8eNJ85/O8NoamqKhfxNRoFtG022TV1QwBVJCvhI0w9MTCd8qmpzkv2augcAd7atO32w4VHJoXE/0DDKiU1jHwxj779exG1ySJLUd0l2oZUYOq+qPgdQVXe3Pf83wKXN4ibgoLbVDwTu6lOokqThdkRV3dUkgK5M8u0d1J3TwYZxP9AwyolNYx8MY++/XsTtnEOSpL5qJgQ9G7ilqt7fVr68rdpvAjc1jy8BXpdk1yRPozVXxFf6Fa8kaXhV1V3N/RbgIlpz0t093ac091ua6h5skKRZmBySJPXbEcAbgCNnXLb+/0lyY5IbgJcCfwBQVTcDFwDfAj4PnOaVyiRJSfZornpJkj2Al9M6sHAJsLqpthq4uHl8CXBSWg4H7ne+IUlq8bQySVJfVdWX6Ty0//IdrPNe4L09C0qSNIomgItaA1LZGfhUVX0+yVeBC5KcCtwBvKapfzmty9hvoHUp+1P6H7IkDSeTQ5IkSZJGTlXdDjyvQ/kPgaM6lBdwWh9Ck6SR42llkiRJkiRJY8yRQ5q3FesuG3QIkiRJkiSpSxw5JEmSJEmSNMZMDkmSJEmSJI0xk0OSJEmSJEljzDmHNBCd5i3aePpxA4hEkiRJkqTx5sghSZIkSZKkMWZySJIkSZIkaYyZHJIkSZIkSRpjzjmkoddpfiJwjiJJkiRJkrrBkUOSJEmSJEljzOSQJEmSJEnSGDM5JEmSJEmSNMZMDkmSJEmSJI0xk0OSJEmSJEljzOSQJEmSJEnSGDM5JEmSJEmSNMZMDkmSJEmSJI0xk0OSJEmSJEljzOSQJEmSJEnSGDM5JEmSJEmSNMZMDkmSJEmSJI0xk0OSpL5KclCSq5PckuTmJG9uyvdJcmWSW5v7vZvyJPlgkg1Jbkhy6GBbIEkaFkl2SvKNJJc2y09Lcm3Tl3wmyeOb8l2b5Q3N8ysGGbckDZuuJYeS7JbkK0m+2XzZf3dT3vEDWpI0trYBa6vq2cDhwGlJngOsA66qqoOBq5plgGOAg5vbGuDD/Q9ZkjSk3gzc0rb8PuDMpi+5Fzi1KT8VuLeqngGc2dSTJDW6OXLoIeDIqnoecAhwdJLDmf0DWpI0hqpqc1V9vXn8AK0v9QcAxwPnNtXOBU5oHh8PfKJargGWJVne57AlSUMmyYHAccBHm+UARwIXNlVm9iXTfcyFwFFNfUkSsHO3NlRVBWxtFndpbkXrA/q3m/JzgXfhUV9JEtAM638+cC0wUVWboZVASrJfU+0A4M621TY1ZZs7bG8NrdFFTExMMDU1Ne+YJnaHtSu3PapsIdsZRlu3bl0ybZnJto0m26ZF+kvgbcBezfKTgfuqavpDfLq/gLa+pKq2Jbm/qf+D/oUrScMrrZxOlzaW7ARcBzwDOAv4c+CaZvgmSQ4C/r6qntth3fYv9C84//zz57zfrVu3sueeey6+AV3S73hu/O79sz43sTvc/ZNHllce8KQ5b2M+dWfTvo32v0s39jdb/bkapvfNMMUCwxXPUonlpS996XVVtarLIY20JHsCXwTeW1WfS3JfVS1re/7eqto7yWXAn1XVl5vyq4C3VdV1O9r+qlWr6mtf+9q84/rQeRdzxo2PPnay8fTj5r2dYTQ1NcXk5OSgw+gJ2zaabNv8JLEvaSR5JXBsVb0xySTwh8ApwD/N+O1xeVWtTHIz8Iqq2tQ8dxtwWFX9sMO2F/y7ZNqWe+5/1HdwWPx3134Zpu9e82Xsg2Hs/deL3yVdGzkEUFUPA4ckWQZcBDy7U7VZ1l0PrIfWF/r5dKbD9sWi3/GcvO6yWZ9bu3Lbo37kbDxxcs7bmE/d2bRvo/3v0o39zVZ/robpfTNMscBwxWMsS1OSXYDPAudV1eea4ruTLG9GDS0HtjTlm4CD2lY/ELirf9FKkobQEcCrkhwL7AY8kdZIomVJdm5GD7X3F9N9yaYkOwNPAu7ptOHF/C6Z1vFAwyK/u/bLKH/fMfbBMPb+60XcPblaWVXdB0zRmmh0WfMBDH6hl6Sx18zxcDZwS1W9v+2pS4DVzePVwMVt5Sc1Vy07HLh/+vQzSdJ4qqp3VNWBVbUCeB3whao6EbgaeHVTbWZfMt3HvLqp371TKCRpxHXzamVPaUYMkWR34NdpTTI62we0JGk8HQG8ATgyyfXN7VjgdOBlSW4FXtYsA1wO3A5sAP4GeOMAYpYkjYa3A29NsoHWnEJnN+VnA09uyt/KI1fElCTR3dPKlgPnNvMOPQ64oKouTfIt4Pwk7wG+wSMf0NKirOh0atoSmRdEWsqauYNmu0LMUR3qF3BaT4OSJI2sqpqiddYCVXU7cFiHOj8FXtPXwCRphHTzamU30LrizMzyjh/QkiRJkiRJGryezDkkSZIkSZKk0WBySJIkSZIkaYyZHJIkSZIkSRpjJockSZIkSZLGWDevViZJ0pLU6eqI4BUSJUmStDQ4ckiSJEmSJGmMmRySJEmSJEkaY55WNmZmOzWiH/tbu3IbJ/d5/53imLZ25TYm+x+KJEmSJElDxZFDkiRJkiRJY8zkkCRJkiRJ0hgzOSRJkiRJkjTGTA5JkiRJkiSNMZNDkiRJkiRJY8zkkCRJkiRJ0hgzOSRJkiRJkjTGTA5JkiRJkiSNMZNDkiRJkiRJY8zkkCRJkiRJ0hgzOSRJkiRJkjTGdh50AN20Yt1l25VtPP24AUSyNHT6e0qSJEmSpKXFkUOSJEmSJEljzOSQJEmSJEnSGDM5JEnquyQfS7IlyU1tZe9K8t0k1ze3Y9uee0eSDUm+k+QVg4lakjRMkuyW5CtJvpnk5iTvbsqfluTaJLcm+UySxzfluzbLG5rnVwwyfkkaJiaHJEmDcA5wdIfyM6vqkOZ2OUCS5wCvA36lWeevk+zUt0glScPqIeDIqnoecAhwdJLDgffR6k8OBu4FTm3qnwrcW1XPAM5s6kmSMDkkSRqAqvoScM8cqx8PnF9VD1XVvwAbgMN6FpwkaSRUy9ZmcZfmVsCRwIVN+bnACc3j45tlmuePSpI+hStJQ21JXa1MkjTy3pTkJOBrwNqquhc4ALimrc6mpmw7SdYAawAmJiaYmpqadwATu8PaldvmVHch2x+krVu3jlzMc2XbRpNt02I1I0mvA54BnAXcBtxXVdMf5O19xgHAnQBVtS3J/cCTgR/M2GZP+pJReT+M8nvX2AfD2PuvF3GbHJIkDYsPA39K66jvnwJnAL8DdDqqW502UFXrgfUAq1atqsnJyXkH8aHzLuaMG+fWPW48cf7bH6SpqSkW8jcZBbZtNNk2LVZVPQwckmQZcBHw7E7Vmvs59Se96ktGpc8Y5feusQ+GsfdfL+I2OSRJGgpVdff04yR/A1zaLG4CDmqreiBwVx9Dm9WKdZd1LN94+nF9jkSSxltV3ZdkCjgcWJZk52b0UHufMd2fbEqyM/Ak5n6KsyQtaSaHhpA/NiSNoyTLq2pzs/ibwPSVzC4BPpXk/cD+wMHAVwYQoiRpiCR5CvDzJjG0O/DrtCaZvhp4NXA+sBq4uFnlkmb5n5rnv1BVHUeiStK4MTkkSeq7JJ8GJoF9k2wC3glMJjmE1hD/jcDvAVTVzUkuAL4FbANOa04jkCSNt+XAuc28Q48DLqiqS5N8Czg/yXuAbwBnN/XPBv42yQZaI4ZeN4igJWkYmRySJPVdVb2+Q/HZHcqm678XeG/vIpIkjZqqugF4fofy2+lwVcuq+inwmj6EJkkjx0vZS5IkSZIkjTGTQ5IkSZIkSWOsa8mhJAcluTrJLUluTvLmpnyfJFcmubW537tb+5QkSZIkSdLidHPk0DZgbVU9m9YlJE9L8hxgHXBVVR0MXNUsS5IkSZIkaQh0LTlUVZur6uvN4weAW4ADgOOBc5tq5wIndGufkiRJkiRJWpyeXK0syQpaVw64Fpioqs3QSiAl2W+WddYAawAmJiaYmpqa8/62bt3K1NQUa1du2+65+WynW6bjWahO7YDZ2zJbfYCJ3Xf8fD89ViwLad9itjGx+2DeH50s9j3TbcMUj7FIkiRJUm91PTmUZE/gs8BbqupHSea0XlWtB9YDrFq1qiYnJ+e8z6mpKSYnJzl53WXbPbfxxLlvp1um41moTu2A2dsyW31oJUXOuLEnOcB5e6xYFtK+xWxj7cptvHYRr1M3LfY9023DFI+xSJIkSVJvdfVqZUl2oZUYOq+qPtcU351kefP8cmBLN/cpSZIkSZKkhevm1coCnA3cUlXvb3vqEmB183g1cHG39ilJkiRJkqTF6eb5RkcAbwBuTHJ9U/bHwOnABUlOBe4AXtPFfUqSJEmSJGkRupYcqqovA7NNMHRUt/YjSZIkSZKk7unqnEOSJEmSJEkaLSaHJEmSJEmSxpjJIUmSJEmSpDHWzQmppSVhxbrLOpZvPP24vm5DkiRJkqR+cOSQJEmSJEnSGDM5JEmSJEmSNMZMDkmSJEmSJI0x5xzS0Jhtnp5h1o2YV6y7jLUrt3HyjG05P5EkSZIkqR8cOSRJkiRJkjTGTA5JkiRJkiSNMZNDkiRJkiRJY8zkkCRJkiRJ0hgzOSRJ6rskH0uyJclNbWX7JLkyya3N/d5NeZJ8MMmGJDckOXRwkUuShkGSg5JcneSWJDcneXNTbl8iSQtgckiSNAjnAEfPKFsHXFVVBwNXNcsAxwAHN7c1wIf7FKMkaXhtA9ZW1bOBw4HTkjwH+xJJWhCTQ5KkvquqLwH3zCg+Hji3eXwucEJb+Seq5RpgWZLl/YlUkjSMqmpzVX29efwAcAtwAPYlkrQgOw86AEmSGhNVtRlaX/qT7NeUHwDc2VZvU1O2eeYGkqyhdUSYiYkJpqam5h/E7rB25bZ5r9duIfvth61btw5tbItl20aTbVM3JFkBPB+4liHuS0bl/TDK711jHwxj779exG1ySJI07NKhrDpVrKr1wHqAVatW1eTk5Lx39qHzLuaMGxfXPW48cf777YepqSkW8jcZBbZtNNk2LVaSPYHPAm+pqh8lnbqMVtUOZU+fADAAACAASURBVH3tS4a1b5hplN+7xj4Yxt5/vYjb08okScPi7ukh/s39lqZ8E3BQW70Dgbv6HJskacgk2YVWYui8qvpcU2xfIkkLYHJIkjQsLgFWN49XAxe3lZ/UXGnmcOD+6VMGJEnjKa0hQmcDt1TV+9uesi+RpAXwtDJJUt8l+TQwCeybZBPwTuB04IIkpwJ3AK9pql8OHAtsAB4ETul7wJKkYXME8AbgxiTXN2V/jH2JJC3I2CaHVqy7rGP5xtOP63MkkjR+qur1szx1VIe6BZzW24gkSaOkqr5M53mEwL5EkubN08okSZIkSZLGmMkhSZIkSZKkMWZySJIkSZIkaYyN7ZxDo2i2eZIkSZIkSZIWypFDkiRJkiRJY8zkkCRJkiRJ0hgzOSRJkiRJkjTGTA5JkiRJkiSNMZNDkiRJkiRJY8zkkCRJkiRJ0hgzOSRJkiRJkjTGdh50AFI3rVh32aBDkCRJkiRppHRt5FCSjyXZkuSmtrJ9klyZ5Nbmfu9u7U+SJEmSJEmL183Tys4Bjp5Rtg64qqoOBq5qliVJkiRJkjQkupYcqqovAffMKD4eOLd5fC5wQrf2J0mSJEmSpMXr9YTUE1W1GaC536/H+5MkSZIkSdI8DM2E1EnWAGsAJiYmmJqamvO6W7duZWpqirUrt2333Gzb6VR3R/XnYzqehZottoWY2L2721uMYYoFWvF0ep3m896Yb3tm20anv0033osLtdj3cDcZiyRJkiT1Vq+TQ3cnWV5Vm5MsB7bMVrGq1gPrAVatWlWTk5Nz3snU1BSTk5Oc3OFKVRtP7LydTnV3VH8+puNZqNliW4i1K7dxxo3DkQMcpligFc9rO7xO83lvzPe1mm0bnf423XgvLtRi38PdZCySJEmS1Fu9Pq3sEmB183g1cHGP9ydJkiRJkqR56Oal7D8N/BPwzCSbkpwKnA68LMmtwMuaZUmSJEmSJA2Jrp3jU1Wvn+Wpo7q1D2mQVnTxdL/F6BTHxtOPG0AkkiRJWiqmv2OuXbntF1Mn+B1TGh+9Pq1MkiRJkiRJQ8zkkCRJkiRJ0hgzOSRJGipJNia5Mcn1Sb7WlO2T5Moktzb3ew86TknSYCX5WJItSW5qK+vYX6Tlg0k2JLkhyaGDi1yShs/wXFd8BDn3y+gblnmEJG3npVX1g7bldcBVVXV6knXN8tsHE5okaUicA/wV8Im2stn6i2OAg5vbrwEfbu4lSThySJI0Go4Hzm0enwucMMBYJElDoKq+BNwzo3i2/uJ44BPVcg2wLMny/kQqScPPkUOSpGFTwBVJCvhIVa0HJqpqM0BVbU6yX6cVk6wB1gBMTEwwNTU1751P7N66UstifOi8i7crW3nAkxa1zW7YunXrgv4mo8C2jSbbph6Yrb84ALizrd6mpmzzzA30qi8Z9vfDdLztsQ97zDON8v+dsQ/GqMbei7hNDkmShs0RVXVX84X+yiTfnuuKTSJpPcCqVatqcnJy3jv/0HkXc8aN3e8eN544/1i6bWpqioX8TUaBbRtNtk19lA5l1alir/qSYegHduTktkvZT8c+7DHPNMr/d8Y+GKMaey/iNjk0B72cl8Y5b9QNs72PZpsDaz7zZTm3lvqtqu5q7rckuQg4DLg7yfLmKPByYMtAg5QkDavZ+otNwEFt9Q4E7up7dJI0pJxzSJI0NJLskWSv6cfAy4GbgEuA1U211cD2521JkjR7f3EJcFJz1bLDgfunTz+TJDlySJI0XCaAi5JAq4/6VFV9PslXgQuSnArcAbxmgDFKkoZAkk8Dk8C+STYB7wROp3N/cTlwLLABeBA4pe8BS9IQMzkkSRoaVXU78LwO5T8Ejup/RJKkYVVVr5/lqe36i6oq4LTeRiRJo8vkkCRJkiRp5MycG3Ptym1MDiYUaeQt+eRQvyd8XrHuMtau3PaL2f6nOYGvYH7vRycrl8aDk75LkiRp0JyQWpIkSZIkaYyZHJIkSZIkSRpjJockSZIkSZLGmMkhSZIkSZKkMWZySJIkSZIkaYwt+auVSZK0VMx2FUOvbiZJkqTFcOSQJEmSJEnSGHPkkCTg0SMS1q7cxsmzjFCYWbedoxckSZIkafQ4ckiSJEmSJGmMmRySJEmSJEkaYyaHJEmSJEmSxphzDs0w21wqw7pdaZj0ci6iTtt2jiNJkiRJWjyTQ5IkDZn5HlAweSpJkqTF8LQySZIkSZKkMebIIUmS+sDTiyVJkjSsTA5JS9go/hidGfPalds4eQTbIUmSJEmjwtPKJEmSJEmSxpjJIUmSJEmSpDHmaWWSJKkrvGqaJEnSaDI5JEnSGJnPXGSzJXZGcT4zSZIkzc7kkKSe6/dogtl+uM5nn522cc7Reyw4JklLlyOmJEnSqOtLcijJ0cAHgJ2Aj1bV6f3YryRp6bAv0VzMNzlsYkcaL/YlktRZz5NDSXYCzgJeBmwCvprkkqr6Vq/3LUlaGuxLJI0ik4/Dxb5Ew+zG797PyTM+M/y86L6Zn8trV25jcjChDJ1+jBw6DNhQVbcDJDkfOB7wQ1iSNFf2JfPU6Ufp2pXbGJYzyofldNN+b0PSQNmXSF003S+uXbntF4ktE1qjK1XV2x0krwaOrqrfbZbfAPxaVb1pRr01wJpm8ZnAd+axm32BH3Qh3G4ZpniMZXbDFM8wxQLDFc9SieWpVfWUbgYzTvrUl0wbpvdct9m20WTbRlMv2mZfsgj2JXNm7INh7IMxqrF3/XdJPw4fpkPZdhmpqloPrF/QDpKvVdWqhazbC8MUj7HMbpjiGaZYYLjiMRY1et6X/GJHS/h1tm2jybaNpqXcthFmXzIHxj4Yxj4Yoxp7L+J+XDc3NotNwEFtywcCd/Vhv5KkpcO+RJK0WPYlkjSLfiSHvgocnORpSR4PvA64pA/7lSQtHfYlkqTFsi+RpFn0/LSyqtqW5E3A/0frkpEfq6qbu7ybRQ377IFhisdYZjdM8QxTLDBc8RiL+tWXTFvKr7NtG022bTQt5baNJPuSOTP2wTD2wRjV2Lsed88npJYkSZIkSdLw6sdpZZIkSZIkSRpSJockSZIkSZLG2Mgnh5IcneQ7STYkWdfnfX8syZYkN7WV7ZPkyiS3Nvd79ymWg5JcneSWJDcnefOA49ktyVeSfLOJ591N+dOSXNvE85lmMsC+SLJTkm8kuXQIYtmY5MYk1yf5WlM2qNdqWZILk3y7ef/8+wHG8szmbzJ9+1GStwwwnj9o3r83Jfl0874e2PtGvTXI/qQb5tMnpeWDTVtvSHLo4CJ/bPPt40apffPtL5Ps2ixvaJ5fMcj452Ku/e+otW0+ffkovSe1OKPcl3TqR0bBbH3EKJitDxglMz/jR0Wnz/BRkQ6/37qx3ZFODiXZCTgLOAZ4DvD6JM/pYwjnAEfPKFsHXFVVBwNXNcv9sA1YW1XPBg4HTmv+FoOK5yHgyKp6HnAIcHSSw4H3AWc28dwLnNqneADeDNzStjzIWABeWlWHVNWqZnlQr9UHgM9X1bOA59H6Gw0klqr6TvM3OQR4AfAgcNEg4klyAPD7wKqqei6tiStfx+DfN+qBIehPuuEc5t4nHQMc3NzWAB/uU4wLNd8+bpTaN9/+8lTg3qp6BnBmU2/YzbX/HcW2zbUvH6X3pBZoCfQl57B9PzIKZusjRsFsfcAomfkZP0pmfoaPik6/3xZtpJNDwGHAhqq6vap+BpwPHN+vnVfVl4B7ZhQfD5zbPD4XOKFPsWyuqq83jx+g9QY5YIDxVFVtbRZ3aW4FHAlc2O94khwIHAd8tFnOoGLZgb6/VkmeCLwEOBugqn5WVfcNIpYOjgJuq6p/HWA8OwO7J9kZeAKwmeF736g7BtqfdMM8+6TjgU80n9XXAMuSLO9PpPO3gD5uZNq3gP6yvc0XAkc1fdpQmmf/O1Jtm8XIvye1KCPdl8zSjwy9HfQRQ28HfcBImPkZr97bwe+3RRv15NABwJ1ty5sY/AfBRFVthtYHFbBfvwNohmE/H7h2kPE0QwyvB7YAVwK3AfdV1bamSj9fr78E3gb8W7P85AHGAq0P/SuSXJdkTVM2iNfq6cD3gY83w0E/mmSPAcUy0+uATzeP+x5PVX0X+AvgDlpJofuB6xjs+0a9M4z9STfM9r8zsu2dYx83Uu2bZ3/5i7Y1z99Pq08bVvPpf0etbfPpy0fqPakF83UesBl9xEiY2QdU1cjEzvaf8aOk02f4KJjt99uijXpyqNPRpJHJtPZCkj2BzwJvqaofDTKWqnq4OT3oQFpHUp7dqVqv40jySmBLVV3XXjyIWNocUVWH0hp2fFqSl/Rx3+12Bg4FPlxVzwd+TP9OZ5tVM//Eq4D/PsAY9qZ1tO9pwP7AHrRer5nG+jNnCRn0Z0K/jWR759HHjVT75tlfjkzbFtD/jkzbGvPpy0etbVoYX+cBGqbfQfMxsw9I8txBxzQXs3zGj5Jh+T02Xz37/TbqyaFNwEFtywcCdw0olml3Tw8Tbu639GvHSXah9YF4XlV9btDxTGuGuU3ROgd4WXOKDvTv9ToCeFWSjbSG9x5JK8s9iFgAqKq7mvsttObUOYzBvFabgE1tRygupPVhM+j3zTHA16vq7mZ5EPH8OvAvVfX9qvo58Dngf2eA7xv11DD2J90w2//OyLV3nn3cyLUP5txf/qJtzfNPYnhPA5lv/ztKbZtvXz6S70nNm6/zgMzSR4yUtj5gVOZ92u4zPsknBxvS3M3yGT4KZvv9tmijnhz6KnBwWle9eDyt01AuGXBMlwCrm8ergYv7sdPmnPyzgVuq6v1DEM9TkixrHu9O64f2LcDVwKv7GU9VvaOqDqyqFbTeI1+oqhMHEQtAkj2S7DX9GHg5cBMDeK2q6nvAnUme2RQdBXxrELHM8HoeOaWMAcVzB3B4kic0/1/Tf5uBvG/Uc8PYn3TDbP87lwAnpeVw4P7pU2GG0QL6uJFp3wL6y/Y2v5pWnzaUIxMW0P+OTNsW0JePzHtSi7JU+5KhtoM+YujN0gd8e7BRzc0sn/H/ccBhzckOPsOH3g5+v3Vl4yN9A44F/pnW+fl/0ud9f5rWXCQ/p5XBO5XWufFXAbc29/v0KZYX0Rq2egNwfXM7doDx/CrwjSaem4D/0pQ/HfgKsIHWKUO79vk1mwQuHWQszX6/2dxunn7fDvC1OgT4WvNa/R2w96BiaeJ5AvBD4EltZYP627ybVgd9E/C3wK6Dfg976+nrPbD+pEvxz7lPonXqw1lNW2+kdVW+gbdhB22bVx83Su2bb38J7NYsb2ief/qg2zDHdj5m/ztKbZtvXz5K70lvi35vjGxf0qkfGXRMc4y7Yx8x6LjmGHvHPmDUbu2f8aNwm+0zfFRudPj91o3tptm4JEmSJEmSxtCon1YmSZIkSZKkRTA5JEmSJEmSNMZMDkmSJEmSJI0xk0OSJEmSJEljzOSQJEmSJEnSGDM5JEmSJEmSNMZMDkmSJEmSJI0xk0OSJEmSJEljzOSQJEmSJEnSGDM5JEmSJEmSNMZMDkmSJEmSJI0xk0OSJEmSJEljzOSQJEmSJEnSGDM5JEmSJEmSNMZMDkmSJEmSJI0xk0OSJEmSJEljzOSQJEmSJEnSGDM5JEmSJEmSNMZMDkmSJEmSJI0xk0OSJEmSJEljzOSQJEmSJEnSGDM5JEmSJEmSNMZMDkmSJEmSJI0xk0OSJEmSJEljzOSQJEmSJEnSGDM5JEmSJEmSNMZMDkmSJEmSJI0xk0OSJEmSJEljzOSQJEmSJEnSGDM5JEmSJEmSNMZMDkmSJEmSJI0xk0OSJEmSJEljzOSQJEmSJEnSGDM5JEmSJEmSNMZMDkmSJEmSJI0xk0OSJEmSJEljzOSQNGBJppL87qDjkCTtWJLJJJsGHYckabQkOTHJFW3LleQZg4xJmsnkkPoqycYkP0myNcndST6eZM9Bx9VLSd6V5JODjkOS9Gjj2CdJknonyYuS/K8k9ye5J8n/TPLCqjqvql4+x208PskZSTY1/dO/JDmz17FLJoc0CL9RVXsChwIvBP7zgOPpmSQ7DzoGSdIOjU2fJEnqnSRPBC4FPgTsAxwAvBt4aJ6begewCjgM2At4KfCN7kUqdWZySANTVd8F/h54bpJTktyS5IEktyf5vel6SfZNcmmS+5oM/D8meVzz3NuTfLdZ7ztJjmrKH5dkXZLbkvwwyQVJ9mmeW9EM5Vyd5I4kP0jyJ2372z3JuUnubWJ6W/tpBEn2T/LZJN9vMvm/3/bcu5JcmOSTSX4EnDyz3UleluTbzRGFvwLS9T+uJGleZvRJ+zSjiO5q+oK/67ROWz/zQJJvJfnNtueekeSLzWf9D5J8pilPkjOTbGmeuyHJc/vTSklSD/0yQFV9uqoerqqfVNUVVXVDkpOTfHlG/WOb3z0/SPLn079vaB2ouKiq7qqWjVX1iemVmlGv72j6nXub/mq3PrVRS5jJIQ1MkoOAY2llwrcArwSeCJwCnJnk0KbqWmAT8BRgAvhjoJI8E3gT8MKq2gt4BbCxWef3gROA/wDsD9wLnDUjhBcBzwSOAv5Lkmc35e8EVgBPB14G/Me2mB8H/A/gm7SOBhwFvCXJK9q2ezxwIbAMOG9Gm/cFPkvryPS+wG3AEY/915Ik9dKMPulvgScAvwLsB8w2nP824MXAk2gdHf5kkuXNc38KXAHsDRxI60gywMuBl9D6EbEM+C3gh11ujiSp//4ZeLg5yHxMkr0fo/5v0hohdCit3w+/05RfA7w1yRuTrEzS6UDyibR++/w7Wv2Jo161aCaHNAh/l+Q+4MvAF4H/VlWXVdVtTXb8i7S+UL+4qf9zYDnw1Kr6eVX9Y1UV8DCwK/CcJLs0WfXbmnV+D/iTqtpUVQ8B7wJePeM0r3c3Gf1v0kr2PK8pf20T071VtQn4YNs6LwSeUlX/tap+VlW3A38DvK6tzj9V1d9V1b9V1U9mtP1Y4FtVdWFV/Rz4S+B7C/gbSpK6Y2af9NfAMcD/1fQDP2/6pe1U1X9vjuz+W1V9BriV1mkA0Oq7ngrsX1U/raovt5XvBTwLSFXdUlWbe9c8SVI/VNWPaB18Llq/D76f5JIkE7Os8r6quqeq7qD1m+D1TfmfAe+jlQD6GvDdJKtnrPtXVXVnVd0DvLdtXWnBTA5pEE6oqmVV9dSqemNV/aTJrl/TnDZ2H60kyr5N/T8HNgBXNEMv1wFU1QbgLbQSP1uSnJ9k/2adpwIXNaei3QfcQiuZ1P7h3J6UeRCYnoR0f+DOtufaHz8V2H96u822/3jGdtvrz/SobTdJrh3VlyT11qP6JOAg4J6quvexVkxyUpLr2/qD5/JI3/U2WqcNfyXJzUl+B6CqvgD8Fa3RrHcnWZ/WPBWSpBHXJPxPrqoDafUJ+9NK/HTS/hvgX5u6NKeknVVVR9AaYfpe4GNtZznMuq60GCaHNHBJdqV1qtVfABNVtQy4nGYunqp6oKrWVtXTgd+gNczyqOa5T1XVi2glbYpWlh1aH5jHNF/4p2+7NXNKPJbNtE4BmHZQ2+M7gX+Zsd29qurYtjr1GNv+xfaaYaIHzV5dktRndwL7JFm2o0pJnkrryPCbgCc3fddNPNJ3fa+q/s+q2p/WaNa/TnPZ4qr6YFW9gNZpa78M/FHPWiNJGoiq+jZwDq0kUSftvwH+N+CuDtv4SVWdRWuKjOfMZ11pvkwOaRg8ntbpYd8HtiU5htacDAAkeWUzsWeAH9EaAfRwkmcmObJJLv0U+EnzHMD/C7y3+fJOkqckOX6O8VwAvCPJ3kkOoPXFf9pXgB+lNRH27kl2SvLcJC+c47YvA34lyf/RnOL2+8AvzXFdSVKPNad4/T2tZM7eSXZJ8pIOVfegdTDg+wBJTqHtB0CS1ySZPtBwb1P34SQvTPJrSXYBfkyr/3oYSdJIS/KsJGunP/ubuexeT2sOoU7+qOlnDvr/2bv/aMnKu8737490fhASA0g4Io12XPbN6LUnhLQEhxnnJJgIJKYz94ISmaSJeFsddCXajunkrjEaM2vhzGA0iSa2IUMTCYRBkb4BYxiSuhlUSAAJTUIiLbah00hLgE4O+OM2fu8ftY8pTtfpPudUnao6Z79fa9WqvZ/97L2/T9Wu2qe+53n2Bt4MzN644C1JppvfGmuaIWXP4+l3LLskydp0b7jz9tl1pUGYHNLYVdXX6SZJrqX7B/SPATt7qqwH/icwA/wZ8NtV1aGbULoUeITuELET6X45Avxms41PJPk63S/lly0wpHfSvQD2XzX7vY7mFpRV9RTd3kunNssfAT5I92KkC2nrI8D5Tdxfbdr2JwuMS5I0Gm+ge22gL9K9YcJb5laoqi8Al9E9Lz0MbODp3+ffB9yeZIbu+ejNVfVXdG+88Lt0z3d/Tfdc8N+WrSWSpFH5Ot3fG7cneYLu74976d5cp58bgDuBu+n+A/nypvzv6J5f/obub41LgP+zudbprI/QvUbrA83jXUNtiVop3UueSJpPkp8GLqiqfzvuWCRJkiS1V5I9wE9U1f8cdyxaXew5JM2R5KQkZyb5piQvopvtv37ccUmSJEmStBzWHLmK1DrPBH4HeCHwOHAN3VsbS5IkSZK06jisTJIkSZIkqcUcViZJkiRJktRiEzms7IQTTqh169Ytap0nnniCY445ZnkCWgHa3H7b3s62w8pq/5133vlIVb1g3HG0yVLOJTBZx5Wx9DdJscBkxWMs/a2WWDyXjJ7nkuEylvlNUjzG0t9qiWXec0lVTdzjpS99aS3Wpz71qUWvs5q0uf22vb1WUvuBO2oCvl/b9FjKuaRqso4rY+lvkmKpmqx4jKW/1RKL5xLPJUthLP1NUixVkxWPsfS3WmKZ71zisDJJkiRJkqQWMzkkSRqLJHuS7Epyd5I7mrLjk9yc5P7m+bimPEnek2R3knuSnDbe6CVJkqTVw+SQJGmcXl5Vp1bVxmZ+G3BLVa0HbmnmAc4B1jePLcD7Rx6pJEmStEqZHJIkTZJNwI5megfwup7yK5uh0rcBxyY5aRwBSpIkSauNySFJ0rgU8IkkdybZ0pRNVdVDAM3ziU35ycCDPevubcokSZIkDWgib2UvSWqFM6tqX5ITgZuTfPEwddOnrA6p1E0ybQGYmpqi0+ksOqiZmZklrbccjKW/SYoFJiseY+nPWCRJOjyTQ5Kksaiqfc3z/iTXA6cDDyc5qaoeaoaN7W+q7wVO6Vl9LbCvzza3A9sBNm7cWNPT04uOq9PpsJT1loOx9DdJscBkxWMs/RmLJEmH57AySdLIJTkmyfNmp4FXAfcCO4HNTbXNwA3N9E7gjc1dy84ADswOP5MkSZI0GHsOSZLGYQq4Pgl0z0UfqaqPJ/kscG2Si4EvA+c39W8CzgV2A08Cbxp9yJKkSZLkWOCDwPfSHWr848CXgI8C64A9wI9U1WPpnnB+k+655Engoqq6awxhS9JEWlXJoXXbblyW7e659NUTv7+tGw5y0QDx9NvncrVv2PtbSNtXwnu4FLNtX63tO9I+d33lwEDH/TBi0NJU1QPAi/uUfxU4q095AZeMIDRJGpp+58Urzj5mDJGsWr8JfLyqzkvyTOA5wNuBW6rq0iTbgG3AW4FzgPXN42XA+5vnZdHvbxT/jpA0yRxWJkmSJGlFSfLNwA8AlwNU1T9W1ePAJmBHU20H8LpmehNwZXXdBhzbXNtOksQCeg4l+RDwGmB/VX1vU/ZR4EVNlWOBx6vq1D7r7gG+DjwFHKyqjUOKW5IkSVJ7fSfwt8B/T/Ji4E7gzcDU7DXpmpsbnNjUPxl4sGf9vU3ZIdevG8adL6eO7vbw7jWuu9RN0h3yjGV+kxSPsfS32mNZyLCyK4D3AVfOFlTVj85OJ7kMOHCY9V9eVY8sNUBJkiRJmmMNcBrws1V1e5LfpDuEbD7pU1b9Kg7jzpfvveoGLtv19J9aey5c/HaGYZLukGcs85ukeIylv9UeyxGHlVXVp4FH+y1rLuz2I8DVQ41KkiRJkua3F9hbVbc389fRTRY9PDtcrHne31P/lJ711wL7RhSrJE28Qa859G+Ah6vq/nmWF/CJJHc23TMlSZIkaSBV9TfAg0lmL3VxFvAFYCewuSnbDNzQTO8E3piuM4ADs8PPJEmD363s9Ry+19CZVbWvGet7c5IvNj2RDjHo2N6ZmRm2bnhqUess1HyxzB1HPM799RvXPOg+l6t9w97fQtq+Et7DpZht+2pt35H2OehxP4wYJEnS2PwscFVzp7IHgDfR/ef3tUkuBr4MnN/UvYnubex3072V/ZtGH64kTa4lJ4eSrAH+D+Cl89Wpqn3N8/4k1wOnA32TQ4OO7e10Olx26xOLWmeh5hsfvFy30F7K/rZuOHjIuOZB97mctwgf5v4W0vaV8B4uxWzbV2v7jrTPfuP5l9O4rhUgSZIOVVV3A/1ueHNWn7oFXLLsQUnSCjXIsLIfBL5YVXv7LUxyTJLnzU4DrwLuHWB/kiRJkiRJGrIjJoeSXA38GfCiJHubLpoAFzBnSFmSb0tyUzM7Bdya5HPAZ4Abq+rjwwtdkiRJkiRJgzrieIyqev085Rf1KdtHdywvVfUA8OIB45MkSZIkSdIyGvRuZZIkSZIkSVrBRncl1xVs3TJeZHcS9jeOfbo/9zeMfW7dMPIwJEmSJGnVseeQJEmSJElSi5kckiRJkiRJajGTQ5IkSZIkSS1mckiSJEmSJKnFTA5JkiRJkiS1mMkhSZIkSZKkFjM5JEmSJEmS1GImhyRJkiRJklrM5JAkSZIkSVKLmRySJEmSJElqMZNDkiRJkiRJLWZySJIkSZIkqcVMDkmSJEmSJLWYySFJkiRJkqQWMzkkSZIkSZLUYiaHJEmSJEmSWszkkCRJkiRJUouZHJIkSZIkSWoxk0OSJEmSJEktdsTkUJIPJdmf5N6esl9O8pUkdzePc+dZ9+wkX0qyO8m2YQYuSZIkSZKkwS2k9TXbcwAAIABJREFU59AVwNl9yt9dVac2j5vmLkxyFPBbwDnA9wCvT/I9gwQrSZIkSZKk4TpicqiqPg08uoRtnw7srqoHquofgWuATUvYjiRJkiRJkpbJINcc+pkk9zTDzo7rs/xk4MGe+b1NmSRJkiQNLMmeJLuaS13c0ZQdn+TmJPc3z8c15UnynuaSF/ckOW280UvS5FizxPXeD/wqUM3zZcCPz6mTPuvVfBtMsgXYAjA1NUWn01lUQDMzM2zd8NSi1llNpo6GrRsOjjuMsbDt7Ww7jL79i/1e0uE1w4/vAL5SVa9J8kK6vUyPB+4C3lBV/5jkWcCVwEuBrwI/WlV7xhS2JGnyvLyqHumZ3wbcUlWXNtc93Qa8le7lLtY3j5fR/U3zslEHK0mTaEnJoap6eHY6ye8CH+tTbS9wSs/8WmDfYba5HdgOsHHjxpqenl5UTJ1Oh8tufWJR66wmWzcc5LJdS831rWy2vZ1th9G3f8+F0yPbV0u8GbgP+OZm/tfoXs/umiQfAC6m+4f7xcBjVfVdSS5o6v3oOAKWJK0Im4DpZnoH0KGbHNoEXFlVBdyW5NgkJ1XVQ2OJUpImyJJ+Vc35Ev13wL19qn0WWN/8J/grwAXAjy0pSknSqpJkLfBq4D8DP58kwCv4xnliB/DLdJNDm5ppgOuA9yVJ88e9JKndCvhEkgJ+p/mH89Tsb5WqeijJiU3d+S578bTk0KAjGqB/7+Zx9UCemZmZmN7PxjK/SYrHWPpb7bEcMTmU5Gq6mfcTkuwF3gFMJzmV7pfxHuAnm7rfBnywqs6tqoNJfgb4Y+Ao4ENV9fmhRi9JWql+A/hF4HnN/LcAj1fV7F/Svdep++c/5ptzy4Gmfu8QAklSO51ZVfuaBNDNSb54mLoLuuzFoCMaAN571Q2H9G4eVw/kTqfDUtqwHIxlfpMUj7H0t9pjOWJyqKpe36f48nnq7gPO7Zm/CTjkNveSpPZK8hpgf1XdmWR6trhP1VrAsrnbHvi/vav9v0JLZSzzm6R4jKW/ccXS77p4k/S6rAbN7w+qan+S6+neMfnh2ZEOSU4C9jfVF3XZC0lqk/ZerESSNC5nAq9Nci7wbLrXHPoN4Ngka5reQ71/sM/+Mb83yRrg+cCj/TY8jP/2rvb/Ci2VscxvkuIxlv7GFctF2248pOyKs4+ZmNdlpUtyDPBNVfX1ZvpVwDuBncBm4NLm+YZmlZ1077h8Dd0LUR/wekOS1DXIrewlSVq0qnpbVa2tqnV0r0f3yaq6EPgUcF5Tbe4f85ub6fOa+l5vSJI0Bdya5HPAZ4Abq+rjdJNCr0xyP/DKZh66IxoeAHYDvwv8h9GHLEmTyZ5DkqRJ8VbgmiTvAv6cbwxhvhz4cJLddHsMXTCm+CRJE6SqHgBe3Kf8q8BZfcoLuGQEoUnSimNySJI0NlXVoXuL4dk/8k/vU+fvgfNHGpgkSZLUIg4rkyRJkiRJajGTQ5IkSZIkSS1mckiSJEmSJKnFTA5JkiRJkiS1mMkhSZIkSZKkFjM5JEmSJEmS1GImhyRJkiRJklrM5JAkSZIkSVKLmRySJEmSJElqMZNDkiRJkiRJLWZySJIkSZIkqcVMDkmSJEmSJLWYySFJkiRJkqQWMzkkSZIkSZLUYiaHJEmSJEmSWszkkCRJkiRJUouZHJIkSZIkSWqxIyaHknwoyf4k9/aU/dckX0xyT5Lrkxw7z7p7kuxKcneSO4YZuCRJkiRJkga3kJ5DVwBnzym7GfjeqvqXwF8AbzvM+i+vqlOrauPSQpQkSZIkSdJyOWJyqKo+DTw6p+wTVXWwmb0NWLsMsUmSJEmSJGmZDeOaQz8O/NE8ywr4RJI7k2wZwr4kSZIkSZI0RGsGWTnJ/w0cBK6ap8qZVbUvyYnAzUm+2PRE6retLcAWgKmpKTqdzqJimZmZYeuGpxa1zmoydTRs3XDwyBVXIdvezrbD6Nu/2O8lSZIkSVoJlpwcSrIZeA1wVlVVvzpVta953p/keuB0oG9yqKq2A9sBNm7cWNPT04uKp9PpcNmtTyxqndVk64aDXLZroFzfimXb29l2GH3791w4PbJ9SZIkSdKoLGlYWZKzgbcCr62qJ+epc0yS581OA68C7u1XV5IkSZIkSeOxkFvZXw38GfCiJHuTXAy8D3ge3aFidyf5QFP325Lc1Kw6Bdya5HPAZ4Abq+rjy9IKSZIkSZIkLckRx2NU1ev7FF8+T919wLnN9APAiweKTpIkSZLmkeQo4A7gK1X1miQvBK4BjgfuAt5QVf+Y5FnAlcBLga8CP1pVe8YUtiRNnGHcrUySJEmSxuHNwH09878GvLuq1gOPARc35RcDj1XVdwHvbupJkhomhyRJkiStOEnWAq8GPtjMB3gFcF1TZQfwumZ6UzNPs/yspr4kiQFvZS9JkiRJY/IbwC/SvRYqwLcAj1fVwWZ+L3ByM30y8CBAVR1McqCp/8jcjSbZAmwBmJqaotPpLDqwqaO7d1XttZTtDMPMzMzY9j2XscxvkuIxlv5WeywmhyRJkiStKEleA+yvqjuTTM8W96laC1j29MKq7cB2gI0bN9b09HS/aof13qtu4LJdT/+ptefCxW9nGDqdDktpw3IwlvlNUjzG0t9qj8XkkCRJkqSV5kzgtUnOBZ4NfDPdnkTHJlnT9B5aC+xr6u8FTgH2JlkDPB94dPRhS9Jk8ppDkiRJklaUqnpbVa2tqnXABcAnq+pC4FPAeU21zcANzfTOZp5m+Serqm/PIUlqI5NDkiRJklaLtwI/n2Q33WsKXd6UXw58S1P+88C2McUnSRPJYWWSJEmSVqyq6gCdZvoB4PQ+df4eOH+kgUnSCmLPIUmSJEmSpBYzOSRJGrkkz07ymSSfS/L5JL/SlL8wye1J7k/y0STPbMqf1czvbpavG2f8kiRJ0mpickiSNA7/ALyiql4MnAqcneQM4NeAd1fVeuAx4OKm/sXAY1X1XcC7m3qSJEmShsDkkCRp5Kprppl9RvMo4BXAdU35DuB1zfSmZp5m+VlJMqJwJUmSpFXN5JAkaSySHJXkbmA/cDPwl8DjVXWwqbIXOLmZPhl4EKBZfoDuXWgkSZIkDci7lUmSxqKqngJOTXIscD3w3f2qNc/9egnV3IIkW4AtAFNTU3Q6nUXHNTMzs6T1loOx9DdJscBkxWMs/Y0rlq0bDh5SNkmviyRJs0wOSZLGqqoeT9IBzgCOTbKm6R20FtjXVNsLnALsTbIGeD7waJ9tbQe2A2zcuLGmp6cXHU+n02Ep6y0HY+lvkmKByYrHWPobVywXbbvxkLIrzj5mYl4XSZJmOaxMkjRySV7Q9BgiydHADwL3AZ8CzmuqbQZuaKZ3NvM0yz9ZVYf0HJIkSZK0ePYckiSNw0nAjiRH0f1HxbVV9bEkXwCuSfIu4M+By5v6lwMfTrKbbo+hC8YRtCRJkrQamRySJI1cVd0DvKRP+QPA6X3K/x44fwShSZIkSa3jsDJJkiRJkqQWMzkkSZIkSZLUYiaHJEmSJEmSWmxByaEkH0qyP8m9PWXHJ7k5yf3N83HzrLu5qXN/ks396kiSJEmSJGk8Ftpz6Arg7Dll24Bbqmo9cEsz/zRJjgfeAbyM7gVG3zFfEkmSJEmSJEmjt6DkUFV9mu6tg3ttAnY00zuA1/VZ9YeAm6vq0ap6DLiZQ5NMkiRJkiRJGpNBrjk0VVUPATTPJ/apczLwYM/83qZMkiRJkiRJE2DNMm8/fcqqb8VkC7AFYGpqik6ns6gdzczMsHXDU4uNb9WYOhq2bjg47jDGwra3s+0w+vYv9ntJkiRJklaCQZJDDyc5qaoeSnISsL9Pnb3AdM/8WqDTb2NVtR3YDrBx48aanp7uV21enU6Hy259YlHrrCZbNxzksl3LneubTLa9nW2H0bd/z4XTI9uXJEmSJI3KIMPKdgKzdx/bDNzQp84fA69KclxzIepXNWWSJEmSJEmaAAu9lf3VwJ8BL0qyN8nFwKXAK5PcD7yymSfJxiQfBKiqR4FfBT7bPN7ZlEmSJEmSJGkCLGg8RlW9fp5FZ/WpewfwEz3zHwI+tKToJEmSJEmStKwGGVYmSZIkSZKkFc7kkCRJkiRJUouZHJIkSZIkSWoxk0OSJEmSJEktZnJIkiRJkiSpxUwOSZIkSVpxkjw7yWeSfC7J55P8SlP+wiS3J7k/yUeTPLMpf1Yzv7tZvm6c8UvSJDE5JEmSJGkl+gfgFVX1YuBU4OwkZwC/Bry7qtYDjwEXN/UvBh6rqu8C3t3UkyRhckiSJEnSClRdM83sM5pHAa8ArmvKdwCva6Y3NfM0y89KkhGFK0kTbc24A5AkSZKkpUhyFHAn8F3AbwF/CTxeVQebKnuBk5vpk4EHAarqYJIDwLcAj8zZ5hZgC8DU1BSdTmfRcU0dDVs3HHxa2VK2MwwzMzNj2/dcxjK/SYrHWPpb7bGYHJIkSZK0IlXVU8CpSY4Frge+u1+15rlfL6E6pKBqO7AdYOPGjTU9Pb3ouN571Q1ctuvpP7X2XLj47QxDp9NhKW1YDsYyv0mKx1j6W+2xOKxMkiRJ0opWVY8DHeAM4Ngks5mZtcC+ZnovcApAs/z5wKOjjVSSJpPJIUmSJEkrTpIXND2GSHI08IPAfcCngPOaapuBG5rpnc08zfJPVtUhPYckqY0cViZJkiRpJToJ2NFcd+ibgGur6mNJvgBck+RdwJ8Dlzf1Lwc+nGQ33R5DF4wjaEmaRCaHJEmSJK04VXUP8JI+5Q8Ap/cp/3vg/BGEJkkrjsPKJEmSJEmSWszkkCRJkiRJUouZHJIkSZIkSWoxk0OSJEmSJEktZnJIkiRJkiSpxbxbmSRJPXZ95QAXbbvxaWV7Ln31mKKRJEmSlp89hyRJkiRJklpsycmhJC9KcnfP42tJ3jKnznSSAz11fmnwkCVJkiRJkjQsSx5WVlVfAk4FSHIU8BXg+j5V/1dVvWap+5EkSZIkSdLyGdawsrOAv6yqvx7S9iRJq1SSU5J8Ksl9ST6f5M1N+fFJbk5yf/N8XFOeJO9JsjvJPUlOG28LJEmSpNVlWBekvgC4ep5l35/kc8A+4Beq6vP9KiXZAmwBmJqaotPpLCqAmZkZtm54alHrrCZTR8PWDQfHHcZY2PZ2th1G3/7Ffi9pXgeBrVV1V5LnAXcmuRm4CLilqi5Nsg3YBrwVOAdY3zxeBry/eZYkSZI0BAMnh5I8E3gt8LY+i+8CvqOqZpKcC/wh3T/uD1FV24HtABs3bqzp6elFxdHpdLjs1icWtc5qsnXDQS7b1c6bz9n2drYdRt/+PRdOj2xfq1lVPQQ81Ex/Pcl9wMnAJmC6qbYD6NBNDm0CrqyqAm5LcmySk5rtSJIkSRrQMH5VnQPcVVUPz11QVV/rmb4pyW8nOaGqHhnCfiVJK1ySdcBLgNuBqdmET1U9lOTEptrJwIM9q+1tyg5JDg3aCxX690gbV6+xmZmZiemxZizzm6R4jKW/ccXSr3frJL0ukiTNGkZy6PXMM6QsybcCD1dVJTmd7jWOvjqEfUqSVrgkzwV+H3hLVX0tybxV+5RVv4qD9kIFeO9VNxzSI21cvcY6nQ5LacNyMJb5TVI8xtLfuGK5aNuNh5RdcfYxE/O6SJI0a6DkUJLnAK8EfrKn7KcAquoDwHnATyc5CPwdcEEzLECS1GJJnkE3MXRVVf1BU/zw7HCxJCcB+5vyvcApPauvpXsdO0mSJElDMFByqKqeBL5lTtkHeqbfB7xvkH1IklaXdLsIXQ7cV1W/3rNoJ7AZuLR5vqGn/GeSXEP3QtQHvN6QJEmSNDztvZKtJGlczgTeAOxKcndT9na6SaFrk1wMfBk4v1l2E3AusBt4EnjTaMOVJEmSVjeTQ5KkkaqqW+l/HSGAs/rUL+CSZQ1KkiRJarFvGncAkiRJkiRJGh+TQ5IkSZIkSS3msDJJkqQB7PrKgUNuWb7n0lePKRpJkqTFs+eQJEmSJElSi5kckiRJkiRJajGTQ5IkSZIkSS1mckiSJEmSJKnFTA5JkiRJkiS1mHcrkyRJkrSiJDkFuBL4VuCfgO1V9ZtJjgc+CqwD9gA/UlWPJQnwm8C5wJPARVV11zhiH5V1zV0Ut244+LQ7Kno3RUn92HNIkiRJ0kpzENhaVd8NnAFckuR7gG3ALVW1HrilmQc4B1jfPLYA7x99yJI0uUwOSZIkSVpRquqh2Z4/VfV14D7gZGATsKOptgN4XTO9Cbiyum4Djk1y0ojDlqSJ5bAySZIkSStWknXAS4Dbgamqegi6CaQkJzbVTgYe7Fltb1P2UJ/tbaHbu4ipqSk6nc6iY5o6ujucq9dStjOI2f3PjWXUcfSamZkZ6/57TVIsMFnxGEt/qz0Wk0OSJEmSVqQkzwV+H3hLVX2te2mh/lX7lFW/ilW1HdgOsHHjxpqenl50XO+96gYu2/X0n1p7Llz8dgZxUc81h3pjGXUcvTqdDkt5PZfDJMUCkxWPsfS32mNxWJkkSZKkFSfJM+gmhq6qqj9oih+eHS7WPO9vyvcCp/SsvhbYN6pYJWnSmRySJEmStKI0dx+7HLivqn69Z9FOYHMzvRm4oaf8jek6AzgwO/xMkuSwMkmSJEkrz5nAG4BdSe5uyt4OXApcm+Ri4MvA+c2ym+jexn433VvZv2m04UrSZDM5JEmSJGlFqapb6X8dIYCz+tQv4JJlDUqSVjCHlUmSJEmSJLWYySFJkiRJkqQWGzg5lGRPkl1J7k5yR5/lSfKeJLuT3JPktEH3KUmSJEmSpOEY1jWHXl5Vj8yz7BxgffN4GfD+5lmSJEmSJEljNophZZuAK6vrNuDYJCeNYL+SJEmSJEk6gmH0HCrgE0kK+J2q2j5n+cnAgz3ze5uyh3orJdkCbAGYmpqi0+ksKoiZmRm2bnhqcZGvIlNHw9YNB8cdxljY9na2HUbf/sV+L0mSJEnSSjCM5NCZVbUvyYnAzUm+WFWf7lne7xaTdUhBN6m0HWDjxo01PT29qCA6nQ6X3frEotZZTbZuOMhlu4Y1SnBlse3tbDuMvv17Lpwe2b4kSZIkaVQGHlZWVfua5/3A9cDpc6rsBU7pmV8L7Bt0v5IkSZIkSRrcQMmhJMcked7sNPAq4N451XYCb2zuWnYGcKCqHkKSJEmSJEljN+h4jCng+iSz2/pIVX08yU8BVNUHgJuAc4HdwJPAmwbcpyRJkiRJkoZkoORQVT0AvLhP+Qd6pgu4ZJD9SJIkSZIkaXmM4lb2kiRJkiRJmlAmhyRJkiRJklrM5JAkSZIkSVKLmRySJEmSJElqMZNDkiRJkiRJLWZySJIkSZIkqcVMDkmSJEmSJLWYySFJ0sgl+VCS/Unu7Sk7PsnNSe5vno9rypPkPUl2J7knyWnji1ySJElafUwOSZLG4Qrg7Dll24Bbqmo9cEszD3AOsL55bAHeP6IYJUmSpFYwOSRJGrmq+jTw6JziTcCOZnoH8Lqe8iur6zbg2CQnjSZSSZIkafVbM+4AJElqTFXVQwBV9VCSE5vyk4EHe+rtbcoemruBJFvo9i5iamqKTqez+CCOhq0bDj6tbCnbGYaZmZmx7XsuY5mfx0x/xnLocTHOWCRJOhyTQ5KkSZc+ZdWvYlVtB7YDbNy4saanpxe9s/dedQOX7Xr66XHPhYvfzjB0Oh2W0oblYCzz85jpz1jgom03HlJ2xdnHTMzrIknSLIeVSZImxcOzw8Wa5/1N+V7glJ56a4F9I45NkiRJWrVMDkmSJsVOYHMzvRm4oaf8jc1dy84ADswOP5MkSZI0OIeVSZJGLsnVwDRwQpK9wDuAS4Frk1wMfBk4v6l+E3AusBt4EnjTyAOWJEmSVjGTQ5Kkkauq18+z6Kw+dQu4ZHkjkiRJktrLYWWSJEmSVpwkH0qyP8m9PWXHJ7k5yf3N83FNeZK8J8nuJPckOW18kUvS5DE5JEmSJGklugI4e07ZNuCWqloP3NLMA5wDrG8eW4D3jyhGSVoRTA5JkiRJWnGq6tPAo3OKNwE7mukdwOt6yq+srtuAY2fvkClJ8ppDkiRJklaPqdk7WlbVQ0lObMpPBh7sqbe3KTvk7pdJttDtXcTU1BSdTmfxQRwNWzccfFrZUrYziNn9z41l1HH0mpmZGev+e01SLDBZ8RhLf6s9FpNDkiRJkla79CmrfhWrajuwHWDjxo01PT296J2996obuGzX039q7blw8dsZxEXbbgS6iaHeWEYdR69Op8NSXs/lMEmxwGTFYyz9rfZYljysLMkpST6V5L4kn0/y5j51ppMcSHJ38/ilwcKVJEmSpHk9PDtcrHne35TvBU7pqbcW2Dfi2CRpYg1yzaGDwNaq+m7gDOCSJN/Tp97/qqpTm8c7B9ifJEmSJB3OTmBzM70ZuKGn/I3NXcvOAA7MDj+TJA0wrKz5Mp0dz/v1JPfRHbf7hSHFJkmSJEl9JbkamAZOSLIXeAdwKXBtkouBLwPnN9VvAs4FdgNPAm8aecCSNMGGcs2hJOuAlwC391n8/Uk+R7fb5i9U1efn2cZAF36bmZlh64anFrXOatLvondtYdvb2XYYffsn5QJ0kiQJqur18yw6q0/dAi5Z3ogkaeUaODmU5LnA7wNvqaqvzVl8F/AdVTWT5FzgD4H1/bYz6IXfOp0Ol936xCKjXz3mXmiuTWx7O9sOo2//OC/gKEmSJEnLZZBrDpHkGXQTQ1dV1R/MXV5VX6uqmWb6JuAZSU4YZJ+SJEmSJEkankHuVhbgcuC+qvr1eep8a1OPJKc3+/vqUvcpSZIkSZKk4RpkPMaZwBuAXUnubsreDnw7QFV9ADgP+OkkB4G/Ay5oxvtKkiRJkiRpAgxyt7JbgRyhzvuA9y11H5IkSZIkSVpeA11zSJIkSZIkSSubySFJkiRJkqQWMzkkSZIkSZLUYiaHJEmSJEmSWszkkCRJkiRJUouZHJIkSZIkSWoxk0OSJEmSJEktZnJIkiRJkiSpxUwOSZIkSZIktZjJIUmSJEmSpBYzOSRJkiRJktRiJockSZIkSZJazOSQJEmSJElSi5kckiRJkiRJarE14w5AkiRJkrQ6rdt24z9Pb91wkIua+T2XvnpcIUnqw55DkiRJkiRJLWZySJIkSZIkqcVMDkmSJEmSJLWY1xySJEmSJGmMdn3lwD9fj2mW12XSKJkckiRJkiStauvmJF5mL45tAkbqcliZJEmSJElSiw2UHEpydpIvJdmdZFuf5c9K8tFm+e1J1g2yP0lSex3pnCNJ0pF4LpGk/pY8rCzJUcBvAa8E9gKfTbKzqr7QU+1i4LGq+q4kFwC/BvzoIAFLktpngeccSZLm5blE0ko0d0gkwBVnHzP0/QxyzaHTgd1V9QBAkmuATUDvl+sm4Jeb6euA9yVJVdUA+5Uktc9CzjmSJB2O5xLpMGaTELPXY5rldZnaIUvN0yQ5Dzi7qn6imX8D8LKq+pmeOvc2dfY283/Z1Hmkz/a2AFua2RcBX1pkSCcAh2y3RdrcftveXiup/d9RVS8YdxAr1ULOOU35oOcSmKzjylj6m6RYYLLiMZb+VkssnksG4LlkIhjL/CYpHmPpb7XE0vdcMkjPofQpm5tpWkidbmHVdmD7koNJ7qiqjUtdf6Vrc/ttezvbDra/ZRZ0Phn0XAKTdVwZS3+TFAtMVjzG0p+xqOG5ZMyMZX6TFI+x9LfaYxnkgtR7gVN65tcC++ark2QN8Hzg0QH2KUlqp4WccyRJOhzPJZI0j0GSQ58F1id5YZJnAhcAO+fU2QlsbqbPAz7p9YYkSUuwkHOOJEmH47lEkuax5GFlVXUwyc8AfwwcBXyoqj6f5J3AHVW1E7gc+HCS3XR7DF0wjKDnMVDXz1Wgze237e3V9va3xnznnGXa3SQdV8bS3yTFApMVj7H0ZyzyXDIZjGV+kxSPsfS3qmNZ8gWpJUmSJEmStPINMqxMkiRJkiRJK5zJIUmSJEmSpBZbFcmhJGcn+VKS3Um2jTueYUtySpJPJbkvyeeTvLkpPz7JzUnub56Pa8qT5D3N63FPktPG24LBJTkqyZ8n+Vgz/8Iktzdt/2hzUUGSPKuZ390sXzfOuIchybFJrkvyxeYY+P62vPdJfq455u9NcnWSZ7fpvddwJflQkv1J7p1n+byfnySbm2Pu/iSb+60/5FgubGK4J8mfJnlxz7I9SXYluTvJHSOIZTrJgWZ/dyf5pZ5lQz3/LiCW/9gTx71JnkpyfLNs2K9L33PvnDojOWYWGMsoj5mFxDOS42aBsYzkuGnOUZ9J8rkmll/pU2fec1WStzXlX0ryQ4PEovEZ9vfigLEc9jt1xLEc8bM6wliO+FkdQ0xP+60zxjiGer4YQjyH/A4aUxwv6jmP3J3ka0neMo5YmngO+Y00lA1X1Yp+0L2Y3F8C3wk8E/gc8D3jjmvIbTwJOK2Zfh7wF8D3AP8F2NaUbwN+rZk+F/gjIMAZwO3jbsMQXoOfBz4CfKyZvxa4oJn+APDTzfR/AD7QTF8AfHTcsQ+h7TuAn2imnwkc24b3HjgZ+Cvg6J73/KI2vfc+hvsAfgA4Dbh3nuV9Pz/A8cADzfNxzfRxyxzLv5rdB3BO72cZ2AOcMMLXZXr2u3dO+dDPv0eKZU7dH6Z7F9Tlel36nnvHccwsMJZRHjMLiWckx81CYhnVcdMcB89tpp8B3A6cMadO33MV3b/rPgc8C3hh8xodNaz3zMdoHsvxvThgPAv+Th1BLIv6rC5zLEf8rI4hpqf91hljHEM9XwwhnkN+B01ATEcBfwN8x5j23/c30jC2vRp6Dp0O7K6qB6rqH4FrgE1jjmmoquqhqrqrmf46cB/dg2IT3Q8MzfPrmulNwJXVdRtwbJKTRhz20CRZC7wa+GAzH+AVwHVNlbltn31NrgPOauqvSEm+me6J/XKAqvrHqnqclrz3dO+oeHSSNcBzgIdoyXuv4auqT9NyKD/EAAAfbUlEQVS9c+Z85vv8/BBwc1U9WlWPATcDZy9nLFX1p82+AG4D1g6yv0FiOYyhn38XGcvrgasH2d8RYpnv3NtrJMfMQmIZ8TGzkNdmPkM9bpYQy7IdN81xMNPMPqN5zL3zy3znqk3ANVX1D1X1V8Buuq+VVpaJ+l0ywPf70A34vTHsWBbyWR2Zub911HWY30Hjdhbwl1X112OMYe5vpH3D2OhqSA6dDDzYM7+XMX3RjELT/fgldDPcU1X1EHS/cIETm2qr7TX5DeAXgX9q5r8FeLyqDjbzve3757Y3yw809Veq7wT+FvjvTVfTDyY5hha891X1FeC/AV+mmxQ6ANxJe957jd58n59xf64upts7ZVYBn0hyZ5ItI4rh+5vu93+U5H9vysb2uiR5Dt1ky+/3FC/b6zLn3Ntr5MfMYWLpNbJj5gjxjPS4OdJrM4rjphkacjewn26CcN5jZs65atzfMxoO38cFWOD32HLHcKTP6ijN/a0zTuP4G2M+8/0OGrcLWMZ/Th1Jv99IVfWJYWx7NSSH+vUMGFvmdzkleS7dP2jeUlVfO1zVPmUr8jVJ8hpgf1Xd2Vvcp2otYNlKtIZud+D3V9VLgCfoDiObz6ppf7rXUdpEt3v9twHH0B0qMddqfe81evMdQ2M7tpK8nO4P/bf2FJ9ZVafR/TxckuQHljmMu+h2nX4x8F7gD2fD61N3VJ+5Hwb+pKp6/yO+LK/LEc69Iz1mFvJ3wCiPmSPEM9LjZoF/Iy37cVNVT1XVqXR7bp2e5HvnhtpvtcOUa2XxfTyCRfyeWVYL+KyOxDy/dcZp1H9jHM5ifwctu3Svdfpa4H+MMYZDfiMl+ffD2PZqSA7tBU7pmV/LkLpVTZIkz6D7RXpVVf1BU/zw7JCh5nl/U76aXpMzgdcm2UO3a+4r6GbXj2260cHT2/fPbW+WP58J6U67RHuBvT3/zbiO7pdkG977HwT+qqr+tqr+P+AP6F5Toy3vvUZvvs/PWD5XSf4l3S7mm6rqq7PlVbWved4PXM8yDz2pqq/Ndr+vqpuAZyQ5gfF+3xzyX7vleF3mOff2Gtkxs4BYRnrMHCmeUR43C3ltGiM5bprtPQ50OHQ44XznqtV0/m4z38fDWMRndWQO81kdlUN+6yT5vTHFMvK/MY5gvt9B43QOcFdVPTzGGOb7jTSw1ZAc+iywPt07GD2T7ol/55hjGqpmLPrlwH1V9es9i3YCs3dA2Qzc0FP+xnSdQber2UMjC3iIquptVbW2qtbRfW8/WVUXAp8CzmuqzW377GtyXlN/xf7Hpqr+BngwyYuaorOAL9CC955uV8kzkjyn+QzMtr0V773GYr7Pzx8Dr0pyXPPfmlc1ZcsmybfTPdm/oar+oqf8mCTPm51uYlnWu9Ak+dbZ63clOZ3u3w5fZUzn3yTPB/4t3/jsL8vrcphzb6+RHDMLiWWUx8wC4xnJcbPA92kkx02SFyQ5tpk+mu4f8F+cU22+c9VO4IJ072b2QmA98JmlxqKxWfW/S5ZqoZ/VEcWykM/qSMzzW2covUAWaxx/YxzOYX4HjdOyXu9wgfr9RrpvGBtec+Qqk62qDib5Gbp/dB0FfKiqPj/msIbtTOANwK50x8YCvB24FLg2ycV0D5Lzm2U30b2Dym7gSeBNow13JN4KXJPkXcCf01yorHn+cJLddP8Td8GY4humnwWuav7IeIDu+/lNrPL3vqpuT3Id3aEJB+m+z9uBG2nPe68hSnI13TsonZBkL/AOuhehpKo+wDyfn6p6NMmv0v2jH+Cdc4alLEcsv0T3OiS/3fy+PlhVG4Ep4PqmbA3wkar6+DLHch7w00kOAn9H926BBQz9/LuAWAD+HfCJqnqiZ9Whvy7Mf+799p54RnXMLCSWkR0zC4xnVMfNQmKB0Rw3JwE7khxFc56uqo8leSdwR1XtZJ5zVVV9Psm1dH/4HAQuqaqnBohFYzBpv0v6fadW1eWHX2vZ9P2sNj0LR63vZ3UMcUya5ThfDKrf76CxSPe6da8EfnJcMcBhfyMNLP5jXZIkSZIkqb1Ww7AySZIkSZIkLZHJIUmSJEmSpBYzOSRJkiRJktRiJockSZIkSZJazOSQJEmSJElSi5kckiRJkiRJajGTQ5IkSZIkSS1mckiSJEmSJKnFTA5JkiRJkiS1mMkhSZIkSZKkFjM5JEmSJEmS1GImhyRJkiRJklrM5JAkSZIkSVKLmRySJEmSJElqMZNDkiRJkiRJLWZySJIkSZIkqcVMDkmSJEmSJLWYySFJkiRJkqQWMzkkSZIkSZLUYiaHJEmSJEmSWszkkCRJkiRJUouZHJIkSZIkSWoxk0OSJEmSJEktZnJIkiRJkiSpxUwOSZIkSZIktZjJIUmSJEmSpBYzOSRJkiRJktRiJockSZIkSZJazOSQJEmSJElSi5kckiRJkiRJajGTQ5IkSZIkSS1mckiSJEmSJKnFTA5JkiRJkiS1mMkhSZIkSZKkFjM5JEmSJEmS1GImhyRJkiRJklrM5JBaL8kHkvynZdjuLyf5vWFvV5IkSZKkYTI5pImV5F8n+dMkB5I8muRPknzfsPdTVT9VVb867O1KkiRJkrQSrBl3AFI/Sb4Z+Bjw08C1wDOBfwP8wyK3EyBV9U9DD1KSJEmSpFXAnkOaVP8bQFVdXVVPVdXfVdUnquqeucO1kqxLUknWNPOdJP85yZ8ATwJvT3JH78aT/FySnc30FUne1Uzfl+Q1PfXWJHkkyWnN/BlNb6bHk3wuyXRP3Rcm+X+TfD3JzcAJy/XiSJIkSZI0LCaHNKn+AngqyY4k5yQ5bpHrvwHYAjwPeC/woiTre5b/GPCRPutdDby+Z/6HgEeq6q4kJwM3Au8Cjgd+Afj9JC9o6n4EuJNuUuhXgc2LjFmSJEmSpJEzOaSJVFVfA/41UMDvAn+bZGeSqQVu4oqq+nxVHayqA8ANNEmfJkn0L4Cdfdb7CPDaJM9p5nuTSP8euKmqbqqqf6qqm4E7gHOTfDvwfcB/qqp/qKpPA//PYtstSZIkSdKomRzSxKqq+6rqoqpaC3wv8G3Abyxw9QfnzH+Eb/QI+jHgD6vqyT773A3cB/xwkyB6Ld9IDn0HcH4zpOzxJI/TTWCd1MT2WFU90bO5v15grJIkSZIkjY0XpNaKUFVfTHIF8JPAXcBzehZ/a79V5sx/Ajghyal0k0Q/d5jdzQ4t+ybgC03CCLoJpw9X1f81d4Uk3wEcl+SYngTRt/eJQ5IkSZKkiWLPIU2kJP8iydYka5v5U+gmbG4D7gZ+IMm3J3k+8LYjba+qDgLXAf+V7vWCbj5M9WuAV9G9U1rvdYl+j26Poh9KclSSZyeZTrK2qv6a7hCzX0nyzCT/GvjhxbZbkiRJkqRRMzmkSfV14GXA7UmeoJsUuhfY2lzr56PAPXQvAP2xBW7zI8APAv+jSRb1VVUPAX8G/KtmP7PlDwKbgLcDf0u3J9F/5Bufox9rYn4UeAdw5QLjkiRJkiRpbFLlqBdJkiRJkqS2sueQJEmSJElSi5kckiRJkiRJajGTQ5IkSZIkSS1mckiSJEmSJKnF1ow7gH5OOOGEWrdu3aLXe+KJJzjmmGOGH9CEsH0r32pvo+2b35133vlIVb1gyCFJkiRJ0sAmMjm0bt067rjjjkWv1+l0mJ6eHn5AE8L2rXyrvY22b35J/nq40UiSJEnScDisTJIkSZIkqcVMDkmSJEmSJLWYySFJkiRJkqQWMzkkSZIkSZLUYiaHJEmSJEmSWszkkCRJkiRJUouZHJIkSZIkSWoxk0OSJEmSJEktZnJIkiRJkiSpxdaMO4Bh2vWVA1y07canle259NVjikaSJEmSJGny2XNIkiRJkiSpxUwOSZIkSZIktZjJIUmSJEmSpBYzOSRJkiRJktRiJockSZIkSZJazOSQJEmSJElSi5kckiRJkiRJajGTQ5IkSZIkSS1mckiSJEmSJKnFTA5JkiRJkiS1mMkhSZIkSZKkFjM5JEmSJEmS1GImhyRJkiRJklrM5JAkSZIkSVKLmRySJEmSJElqsSUlh5LsSbIryd1J7mjKjk9yc5L7m+fjmvIkeU+S3UnuSXLaMBsgSZIkSZKkpRuk59DLq+rUqtrYzG8Dbqmq9cAtzTzAOcD65rEFeP8A+5QkSZIkSdIQDXNY2SZgRzO9A3hdT/mV1XUbcGySk4a4X0mSJEmSJC1RqmrxKyV/BTwGFPA7VbU9yeNVdWxPnceq6rgkHwMurapbm/JbgLdW1R1ztrmFbs8ipqamXnrNNdcsOq79jx7g4b97etmGk5+/6O1MqpmZGZ773OeOO4xls9rbB6u/jbZvfi9/+cvv7OlpKUmSJEkTY80S1zuzqvYlORG4OckXD1M3fcoOyUhV1XZgO8DGjRtrenp60UG996obuGzX05u058LFb2dSdTodlvK6rBSrvX2w+tto+yRJkiRp5VnSsLKq2tc87weuB04HHp4dLtY872+q7wVO6Vl9LbBvqQFLkiRJkiRpeBadHEpyTJLnzU4DrwLuBXYCm5tqm4EbmumdwBubu5adARyoqocGjlySJEmSJEkDW8qwsing+iSz63+kqj6e5LPAtUkuBr4MnN/Uvwk4F9gNPAm8aeCopf+/vbuN0ews7wP+v+LlTTixCW5XlncbW2Ij4UITyIq44kPXOKrWbsXyASqQU2y06n4hbVJQm01bKX37gBu5rkCUdlsjm8jJ4tKXXQERioxHtFVNA6W1MRZi61pmYws3sdl2RUjq5OqHOUb7MnjneeaZZ2fm/v2k0Zxzn3vOua6Z2ZX2v+c+BwAAAFiImcOh7n4yyU+tMf77SW5ZY7yTfHCu6gAAAADYVIt8lT0AAAAA24xwCAAAAGBgwiEAAACAgQmHAAAAAAYmHAIAAAAYmHAIAAAAYGDCIQAAAICBCYcAAAAABiYcAgAAABiYcAgAAABgYMIhAAAAgIEJhwAAAAAGJhwCAAAAGJhwCAAAAGBgwiEAAACAgQmHAAAAAAYmHAIAAAAYmHAIAAAAYGDCIQAAAICBCYcAAAAABiYcAgAAABiYcAgAAABgYMIhAAAAgIEJhwAAAAAGJhwCAAAAGJhwCAAAAGBgwiEAAACAgQmHAAAAAAYmHAIAAAAYmHAIAAAAYGBzhUNVdUVVfa2qPjvt31BVX66qb1XVp6vqldP4q6b9U9Px6xdXOgAAAAAbNe+dQ7+Y5Ilz9u9Kck9370vyQpLD0/jhJC909xuS3DPNAwAAAGCLmDkcqqo9Sf5Skn897VeSdyT5zDTl/iTvmrYPTfuZjt8yzQcAAABgC5jnzqF/luRvJ/mTaf/1Sb7b3S9O+6eTXDdtX5fk20kyHT8zzQcAAABgC9g1y+Sq+stJnuvur1bVgZeG15ja6zh24bmPJDmSJLt3787KysospSVJdr8m+fCbXzxvbJ7zbFVnz57dUf1caKf3l+z8HvUHAACw/cwUDiV5e5J3VtVtSV6d5MeyeifR1VW1a7o7aE+SZ6b5p5PsTXK6qnYluSrJ82uduLuPJTmWJPv37+8DBw7MWFrysQdO5O7Hzm/pqdtnP89WtbKyknm+L9vFTu8v2fk96g8AAGD7mWlZWXf/Snfv6e7rk7w3yRe7+/YkDyd59zTtjiQnpu2T036m41/s7jXvHAIAAABg+eZ9W9mFfjnJh6rqVFafKXTvNH5vktdP4x9KcnRB1wMAAABgAWZdVvYD3b2SZGXafjLJ29aY8/0k75n3GgAAAABsrkXdOQQAAADANiQcAgAAABiYcAgAAABgYMIhAAAAgIEJhwAAAAAGJhwCAAAAGJhwCAAAAGBgwiEAAACAgQmHAAAAAAYmHAIAAAAYmHAIAAAAYGDCIQAAAICBCYcAAAAABiYcAgAAABiYcAgAAABgYMIhAAAAgIEJhwAAAAAGtutyFwCwFV1/9HMXjd138LWXoRIAAIDN5c4hAAAAgIEJhwAAAAAGJhwCAAAAGJhwCAAAAGBgwiEAAACAgQmHAAAAAAYmHAIAAAAYmHAIAAAAYGDCIQAAAICBCYcAAAAABiYcAgAAABiYcAgAAABgYMIhAAAAgIHNHA5V1aur6r9W1f+oqser6h9M4zdU1Zer6ltV9emqeuU0/qpp/9R0/PrFtgAAAADAvOa5c+gPk7yju38qyU8nOVhVNyW5K8k93b0vyQtJDk/zDyd5obvfkOSeaR4AAAAAW8DM4VCvOjvtvmL66CTvSPKZafz+JO+atg9N+5mO31JVNXfFAAAAACxMdffsX1R1RZKvJnlDko8n+bUkj0x3B6Wq9ib5re5+U1V9PcnB7j49HfufSX62u3/vgnMeSXIkSXbv3v0zx48fn7mu554/k+/8wfljb77uqpnPs1WdPXs2V1555eUuY9Ps9P6Snd/jTurvsd89c9HYDVddMXd/N99881e7e/9G6wIAAFi0XfN8UXf/cZKfrqqrk/z7JG9ca9r0ea27hC5KpLr7WJJjSbJ///4+cODAzHV97IETufux81t66vbZz7NVraysZJ7vy3ax0/tLdn6PO6m/O49+7qKx+w6+dsf0BwAA8JINva2su7+bZCXJTUmurqqXkpk9SZ6Ztk8n2Zsk0/Grkjy/kesCAAAAsBjzvK3sT013DKWqXpPk55I8keThJO+ept2R5MS0fXLaz3T8iz3PWjYAAAAAFm6eZWXXJrl/eu7QjyR5sLs/W1XfSHK8qv5xkq8luXeaf2+SX6+qU1m9Y+i9C6gbAAAAgAWYORzq7keTvGWN8SeTvG2N8e8nec9c1QEAAACwqTb0zCEAAAAAtjfhEAAAAMDAhEMAAAAAAxMOAQAAAAxMOAQAAAAwMOEQAAAAwMCEQwAAAAADEw4BAAAADEw4BAAAADAw4RAAAADAwIRDAAAAAAMTDgEAAAAMTDgEAAAAMDDhEAAAAMDAhEMAAAAAAxMOAQAAAAxMOAQAAAAwMOEQAAAAwMCEQwAAAAADEw4BAAAADEw4BAAAADAw4RAAAADAwIRDAAAAAAMTDgEAAAAMTDgEAAAAMDDhEAAAAMDAhEMAAAAAAxMOAQAAAAxMOAQAAAAwMOEQAAAAwMBmCoeqam9VPVxVT1TV41X1i9P4j1fVb1fVt6bPr5vGq6o+WlWnqurRqnrrZjQBAAAAwHxmvXPoxSQf7u43JrkpyQer6sYkR5M81N37kjw07SfJrUn2TR9HknxiIVUDAAAAsBAzhUPd/Wx3/7dp+/8meSLJdUkOJbl/mnZ/kndN24eSfKpXPZLk6qq6diGVAwAAALBh1d3zfWHV9Um+lORNSZ7u7qvPOfZCd7+uqj6b5CPd/Z+m8YeS/HJ3f2WN8x3J6t1F2b17988cP3585pqee/5MvvMH54+9+bqrZj7PVnX27NlceeWVl7uMTbPT+0t2fo87qb/HfvfMRWM3XHXF3P3dfPPNX+3u/RutCwAAYNF2zfNFVXVlkn+b5Je6+/9U1Q+dusbYmmlUdx9LcixJ9u/f3wcOHJi5ro89cCJ3P3Z+S0/dPvt5tqqVlZXM833ZLnZ6f8nO73En9Xfn0c9dNHbfwdfumP4AAABeMvPbyqrqFVkNhh7o7n83DX/npeVi0+fnpvHTSfae8+V7kjwzf7kAAAAALNKsbyurJPcmeaK7/+k5h04muWPaviPJiXPG3z+9teymJGe6+9kN1gwAAADAgsy6rOztSf5qkseq6r9PY38nyUeSPFhVh5M8neQ907HPJ7ktyakk30vygQ1XDAAAAMDCzBQOTQ+W/mEPGLpljfmd5INz1AUAAADAEsz8zCEAAAAAdg7hEAAAAMDAhEMAAAAAAxMOAQAAAAxMOAQAAAAwMOEQAAAAwMCEQwAAAAADEw4BAAAADEw4BAAAADAw4RAAAADAwIRDAAAAAAMTDgEAAAAMTDgEAAAAMDDhEAAAAMDAhEMAAAAAAxMOAQAAAAxMOAQAAAAwMOEQAAAAwMCEQwAAAAADEw4BAAAADEw4BAAAADAw4RAAAADAwIRDAAAAAAMTDgEAAAAMTDgEAAAAMDDhEAAAAMDAhEMAAAAAAxMOAQAAAAxMOAQAAAAwMOEQAAAAwMBmDoeq6pNV9VxVff2csR+vqt+uqm9Nn183jVdVfbSqTlXVo1X11kUWDwAAAMDGzHPn0H1JDl4wdjTJQ929L8lD036S3Jpk3/RxJMkn5isTAAAAgM0wczjU3V9K8vwFw4eS3D9t35/kXeeMf6pXPZLk6qq6dt5iAQAAAFisRT1zaHd3P5sk0+c/PY1fl+Tb58w7PY0BAAAAsAXs2uTz1xpjvebEqiNZXXqW3bt3Z2VlZeaL7X5N8uE3v3je2Dzn2arOnj27o/q50E7vL9n5Pe6k/i78uyTZWf0BAAC8ZFHh0Heq6trufnZaNvbcNH46yd5z5u1J8sxaJ+juY0mOJcn+/fv7wIEDMxfxsQdO5O7Hzm/pqdtnP89WtbKyknm+L9vFTu8v2fk97qT+7jz6uYvG7jv42h3THwAAwEsWtazsZJI7pu07kpw4Z/z901vLbkpy5qXlZwAAAABcfjPfOVRVv5nkQJJrqup0kl9N8pEkD1bV4SRPJ3nPNP3zSW5LcirJ95J8YAE1AwAAALAgM4dD3f2+H3LoljXmdpIPznoNAAAAAJZjUcvKAAAAANiGhEMAAAAAAxMOAQAAAAxMOAQAAAAwMOEQAAAAwMCEQwAAAAADEw4BAAAADEw4BAAAADAw4RAAAADAwIRDAAAAAAMTDgEAAAAMTDgEAAAAMDDhEAAAAMDAhEMAAAAAAxMOAQAAAAxMOAQAAAAwMOEQAAAAwMCEQwAAAAADEw4BAAAADEw4BAAAADAw4RAAAADAwIRDAAAAAAMTDgEAAAAMTDgEAAAAMDDhEAAAAMDAhEMAAAAAAxMOAQAAAAxMOAQAAAAwMOEQAAAAwMCEQwAAAAADEw4BAAAADGwp4VBVHayqb1bVqao6uoxrAgAAAHBpmx4OVdUVST6e5NYkNyZ5X1XduNnXBQAAAODSlnHn0NuSnOruJ7v7j5IcT3JoCdcFAAAA4BJ2LeEa1yX59jn7p5P87IWTqupIkiPT7tmq+uYc17omye+dd9675jjL1nVRfzvMTu8v2fk97uj+br5rQ/39xCJrAQAAWJRlhEO1xlhfNNB9LMmxDV2o6ivdvX8j59jK9Lf97fQe9QcAALD9LGNZ2ekke8/Z35PkmSVcFwAAAIBLWEY49DtJ9lXVDVX1yiTvTXJyCdcFAAAA4BI2fVlZd79YVb+Q5AtJrkjyye5+fJMut6FladuA/ra/nd6j/gAAALaZ6r7o8T8AAAAADGIZy8oAAAAA2KKEQwAAAAAD23bhUFUdrKpvVtWpqjq6xvFXVdWnp+Nfrqrrl1/lxqyjxw9V1Teq6tGqeqiqfuJy1DmvS/V3zrx3V1VX1bZ6dfh6+quqvzL9DB+vqt9Ydo0btY7f0T9TVQ9X1dem39PbLked86qqT1bVc1X19R9yvKrqo1P/j1bVW5ddIwAAwKJsq3Coqq5I8vEktya5Mcn7qurGC6YdTvJCd78hyT1J7lpulRuzzh6/lmR/d/+5JJ9J8k+WW+X81tlfqupHk/yNJF9eboUbs57+qmpfkl9J8vbu/rNJfmnphW7AOn+Gfy/Jg939lqy+ofCfL7fKDbsvycGXOX5rkn3Tx5Ekn1hCTQAAAJtiW4VDSd6W5FR3P9ndf5TkeJJDF8w5lOT+afszSW6pqlpijRt1yR67++Hu/t60+0iSPUuucSPW8zNMkn+U1dDr+8ssbgHW099fS/Lx7n4hSbr7uSXXuFHr6bGT/Ni0fVWSZ5ZY34Z195eSPP8yUw4l+VSveiTJ1VV17XKqAwAAWKztFg5dl+Tb5+yfnsbWnNPdLyY5k+T1S6luMdbT47kOJ/mtTa1osS7ZX1W9Jcne7v7sMgtbkPX8/H4yyU9W1X+uqkeq6uXuUNmK1tPj30/y81V1Osnnk/z15ZS2NLP+OQUAANiydl3uAma01h1APcecrWzd9VfVzyfZn+QvbGpFi/Wy/VXVj2R1OeCdyypowdbz89uV1eVIB7J619d/rKo3dfd3N7m2RVlPj+9Lcl93311Vfz7Jr089/snml7cU2/3vGQAAgB/YbncOnU6y95z9Pbl4ucoP5lTVrqwuaXm55SFbzXp6TFX9XJK/m+Sd3f2HS6ptES7V348meVOSlap6KslNSU5uo4dSr/d39ER3/7/u/l9JvpnVsGi7WE+Ph5M8mCTd/V+SvDrJNUupbjnW9ecUAABgO9hu4dDvJNlXVTdU1Suz+qDbkxfMOZnkjmn73Um+2N3b6X/0L9njtOzqX2Y1GNpuz6t52f66+0x3X9Pd13f39Vl9ptI7u/srl6fcma3nd/Q/JLk5SarqmqwuM3tyqVVuzHp6fDrJLUlSVW/Majj0v5da5eY6meT901vLbkpyprufvdxFAQAAzGNbLSvr7her6heSfCHJFUk+2d2PV9U/TPKV7j6Z5N6sLmE5ldU7ht57+Sqe3Tp7/LUkVyb5N9Oztp/u7ndetqJnsM7+tq119veFJH+xqr6R5I+T/K3u/v3LV/Vs1tnjh5P8q6r6m1ldbnXndgppq+o3s7rs75rpuUm/muQVSdLd/yKrz1G6LcmpJN9L8oHLUykAAMDG1Tb69xoAAAAAC7bdlpUBAAAAsEDCIQAAAICBCYcAAAAABiYcAgAAABiYcAgAAABgYMIhAAAAgIEJhwAAAAAG9v8B5Y5WHQPP/PUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "train.hist(bins = 50, figsize= (20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By observing the plots, I have made few decisions:\n",
    "\n",
    "- We can drop __PassengerId__ from our model as survival does not seem to depend on it by it's consistent patterns which is probably because the bins contain odd numbers which is why either the value is 17.5 or it is 16.5.\n",
    "\n",
    "- __Parch__ categorical attribute will get converted into either have parents or children (1) or not (0).\n",
    "\n",
    "- __SibSp__ categorical attribute will get converted into either have siblings/spouse (1) or not (0).\n",
    "\n",
    "- __Pclass__ we may think of converting this into either lower class or not. But right now, haven't decided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Okay, so we have work to do!\n",
    "\n",
    "1. Drop __PassengerId__ and __Cabin__ from the dataset.\n",
    "2. Use One-hot Encoding on __Pclass__.\n",
    "3. Convert __Sex__ into categorical attribute.\n",
    "4. Impute __Age__ with median values.\n",
    "5. Feature scale the __SibSp__ and __Parch__.\n",
    "6. Add a column named __Family__.\n",
    "7. Impute __Embarked__ with most frequent class.\n",
    "8. Drop __Ticket__ and __Name__ for now as they are little more complicated.\n",
    "\n",
    "Let's create our data preprocessing Pipelines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['PassengerId','Cabin','Name','Ticket'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         3    male  22.0      1      0   7.2500        S\n",
       "1         1  female  38.0      1      0  71.2833        C\n",
       "2         3  female  26.0      0      0   7.9250        S\n",
       "3         1  female  35.0      1      0  53.1000        S\n",
       "4         3    male  35.0      0      0   8.0500        S\n",
       "..      ...     ...   ...    ...    ...      ...      ...\n",
       "886       2    male  27.0      0      0  13.0000        S\n",
       "887       1  female  19.0      0      0  30.0000        S\n",
       "888       3  female   NaN      1      2  23.4500        S\n",
       "889       1    male  26.0      0      0  30.0000        C\n",
       "890       3    male  32.0      0      0   7.7500        Q\n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Family'] = X_train['SibSp']+X_train['Parch']+1\n",
    "X_test['Family'] = X_test['SibSp']+X_test['Parch']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry about different libraries, best way to understand their usage is to go through their documentation, so I recommend you to keep the Scikit-Learn documentation handy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a dataframe selector which we can use while apply some specific preprocessing steps on only the selected data attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to do this same thing will be to specify initially which are the numerical and categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['Pclass', 'Embarked']\n",
    "bincat_columns = ['SibSp', 'Sex', 'Parch']\n",
    "numerical_columns = ['Age', 'Fare']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But one disadvantage is that if we run the transformation over categorical_columns, then all the columns will get that processing, which in some cases we would not want to do, but still they are useful, so we'll keep them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class binary_cat(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    It converts the SibSp, Parch and Sex attributes into binary categories\n",
    "    \"\"\"\n",
    "    def fit(self, X,y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X.loc[X.SibSp > 0, 'SibSp'] = 1\n",
    "        X.loc[X.Parch > 0, 'Parch'] = 1\n",
    "        X['Sex'].replace(['male','female'], [1,0],inplace=True)\n",
    "        return X[bincat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_cat = binary_cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        int64\n",
       "Sex          object\n",
       "Age         float64\n",
       "SibSp         int64\n",
       "Parch         int64\n",
       "Fare        float64\n",
       "Embarked     object\n",
       "Family        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Numerical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"select_numeric\", DataFrameSelector([\"Age\", \"Fare\",\"Family\"])),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.56573646, -0.50244517,  0.05915988],\n",
       "       [ 0.66386103,  0.78684529,  0.05915988],\n",
       "       [-0.25833709, -0.48885426, -0.56097483],\n",
       "       ...,\n",
       "       [-0.1046374 , -0.17626324,  1.29942929],\n",
       "       [-0.25833709, -0.04438104, -0.56097483],\n",
       "       [ 0.20276197, -0.49237783, -0.56097483]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_encoder = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "        (\"select_cat\", DataFrameSelector([\"Pclass\", \"Embarked\"])),\n",
    "        (\"imputer\", MostFrequentImputer()),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 1.],\n",
       "       [1., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0., 1.],\n",
       "       [1., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 1., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all the processed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "        (\"bincat\", bin_cat)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.56573646, -0.50244517,  0.05915988, ...,  1.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.66386103,  0.78684529,  0.05915988, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.25833709, -0.48885426, -0.56097483, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.1046374 , -0.17626324,  1.29942929, ...,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.25833709, -0.04438104, -0.56097483, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.20276197, -0.49237783, -0.56097483, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = preprocess_pipeline.fit_transform(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.56573646, -0.50244517,  0.05915988,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "        1.        ,  0.        ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "886    0\n",
       "887    1\n",
       "888    0\n",
       "889    1\n",
       "890    0\n",
       "Name: Survived, Length: 891, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a Machine Learning Model on our processed data\n",
    "\n",
    "Let's try a simple Logistic Regression model, which I think is great binary classifier using sigmoid function to classify. Simple and effective!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, X_val, ytrain, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=300,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(max_iter = 300)\n",
    "\n",
    "log_clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8100558659217877"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a validation set for evaluation gets us 80.4% accuracy.\n",
    "\n",
    "Now, using sklearn k-fold cross validation method for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=300,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(max_iter = 300)\n",
    "\n",
    "log_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8013857677902623"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svm_scores = cross_val_score(log_clf, X_train, y_train, cv=10)\n",
    "svm_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting 80.13% accuracy, Can we do better?\n",
    "\n",
    "Yes, we can try out different values of parameters in our model to see which one gives best result on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'max_iter':[0.7,0.8,0.9,1],\n",
    "    'C':[0.1,0.2,0.3,0.4],\n",
    "    'solver':['newton-cg', 'liblinear'],\n",
    "    'class_weight': [None],\n",
    "    'n_jobs': [-1, 1]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 9 folds for each of 64 candidates, totalling 576 fits\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.717, total=   1.5s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.751, total=   0.7s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.657, total=   0.7s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.734, total=   0.7s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.798, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.764, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.791, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.717, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.751, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.734, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.798, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.764, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.791, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.717, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.751, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.657, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.734, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.798, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.764, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.791, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.717, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.751, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.734, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.798, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.764, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.791, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.717, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.751, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.734, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.798, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.764, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.791, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.717, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.751, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.734, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.798, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.764, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.791, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.717, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.751, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.734, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.798, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.764, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.791, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.778, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.795, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.822, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.801, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.815, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.815, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.791, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.808, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.835, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.717, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.751, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.734, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.798, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.764, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.791, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.778, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.795, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.822, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.801, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.815, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.815, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.791, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.808, total=   0.0s\n",
      "[CV] C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.1, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.835, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.771, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.734, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.805, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.764, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.791, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.771, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.734, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.805, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.764, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.791, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.771, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.734, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.805, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.764, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.791, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.771, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.734, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.805, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.764, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.791, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.771, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.734, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.805, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.764, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.791, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.771, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.734, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.805, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.764, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.791, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.771, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.734, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.805, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.764, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.791, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.791, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.795, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.835, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.798, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.801, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.822, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.785, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.822, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.828, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.771, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.734, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.805, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.764, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.791, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.791, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.795, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.835, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.798, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.801, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.822, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.785, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.822, total=   0.0s\n",
      "[CV] C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.2, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.828, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.771, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.801, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.768, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.795, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.771, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.801, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.768, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.795, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.771, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.801, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.768, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.795, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.771, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.801, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.768, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.795, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.771, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.801, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.768, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.795, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.771, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.801, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.768, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.795, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.771, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.801, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.768, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.795, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.808, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.795, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.835, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.801, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.798, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.825, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.788, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.828, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.825, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.771, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.801, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.673, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.768, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.795, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.808, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.795, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.835, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.801, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.798, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.825, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.788, total=   0.0s\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.828, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.3, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.825, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.774, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.801, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.768, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=newton-cg, score=0.795, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.774, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.801, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.737, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.768, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=newton-cg, score=0.795, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.7, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.774, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.801, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.768, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=newton-cg, score=0.795, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.774, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.801, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.768, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=newton-cg, score=0.795, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.8, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.774, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.801, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.768, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=newton-cg, score=0.795, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=-1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.774, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.801, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.768, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=newton-cg, score=0.795, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=0.9, n_jobs=1, solver=liblinear, score=0.616, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.774, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.801, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.768, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=newton-cg, score=0.795, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.801, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.795, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.832, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.805, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.798, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.825, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.785, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.825, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=-1, solver=liblinear, score=0.825, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.774, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.657, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.801, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.737, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.731, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.768, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=newton-cg, score=0.795, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.801, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.795, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.832, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.805, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.798, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.825, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.785, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.825, total=   0.0s\n",
      "[CV] C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear \n",
      "[CV]  C=0.4, class_weight=None, max_iter=1, n_jobs=1, solver=liblinear, score=0.825, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done 576 out of 576 | elapsed:    7.4s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=3, random_state=1),\n",
       "             error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=300, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'C': [0.1, 0.2, 0.3, 0.4], 'class_weight': [None],\n",
       "                          'max_iter': [0.7, 0.8, 0.9, 1], 'n_jobs': [-1, 1],\n",
       "                          'solver': ['newton-cg', 'liblinear']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(log_clf, param_grid, cv=cv, scoring = 'accuracy', verbose=3)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.3,\n",
       " 'class_weight': None,\n",
       " 'max_iter': 1,\n",
       " 'n_jobs': -1,\n",
       " 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8114478114478114"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis for Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(log_clf, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[479,  70],\n",
       "       [103, 239]], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mt = confusion_matrix(y_train, y_train_pred)\n",
    "conf_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(conf_mt, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7734627831715211"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6988304093567251"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though we are getting over 80% accuracy score but we aren't doing good on precision and recall metrics. And for classification, these metrics provide more picture than only accuracy score.\n",
    "\n",
    "We are also getting 70 false positives and 103 false negatives on our logistic regression model.\n",
    "\n",
    "We need to know why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = cross_val_predict(log_clf, X_train, y_train, cv=3,\n",
    "                             method=\"decision_function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.legend(loc=\"center right\", fontsize=16) # Not shown in the book\n",
    "    plt.xlabel(\"Threshold\", fontsize=16)        \n",
    "    plt.grid(True)                          \n",
    "\n",
    "recall_90_precision = recalls[np.argmax(precisions >= 0.90)]\n",
    "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]\n",
    "\n",
    "plt.figure(figsize=(8, 4))                                                                  \n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.axis([-4, 4, 0, 1])\n",
    "plt.plot([threshold_90_precision, threshold_90_precision], [0., 0.9], \"r:\")             \n",
    "plt.plot([-4, threshold_90_precision], [0.9, 0.9], \"r:\")                                \n",
    "plt.plot([-4, threshold_90_precision], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "plt.plot([threshold_90_precision], [0.9], \"ro\")                                         \n",
    "plt.plot([threshold_90_precision], [recall_90_precision], \"ro\")         \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the precision is little bumpier than recall curve, as we go up the threhold, the precision gets bumpier while the recall is consistent with it's going down trend. At the threshold where precision and recall are equal, the F1 score will be highest. \n",
    "\n",
    "To get an understanding of Classification threshold, do check the link: https://developers.google.com/machine-learning/crash-course/classification/thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_by_threshold(X,k):\n",
    "    df = log_clf.decision_function(X)\n",
    "    \n",
    "    # Set the value of decision threshold.\n",
    "    decision_threshold = k\n",
    "\n",
    "    # Desired prediction to increase precision value.\n",
    "    desired_predict =[]\n",
    "\n",
    "    # Iterate through each value of decision function output\n",
    "    # and if  decision score is > than Decision threshold then,\n",
    "    # append (1) to the empty list ( desired_prediction) else\n",
    "    # append (0).\n",
    "    for i in df:\n",
    "        if i<decision_threshold:\n",
    "            desired_predict.append(0)\n",
    "        else:\n",
    "            desired_predict.append(1)\n",
    "            \n",
    "    return desired_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.767123287671233 -0.6057571964956194\n"
     ]
    }
   ],
   "source": [
    "f1_score1 = 0\n",
    "for i in np.linspace(-4,4,800):\n",
    "    y_pred = prediction_by_threshold(X_val, i)\n",
    "    l = f1_score(y_val, y_pred)\n",
    "    if l > f1_score1:\n",
    "        f1_score1 = l\n",
    "        m = i\n",
    "print(f1_score1, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.8100558659217877 \n",
      "Precision Score : 0.7272727272727273 \n",
      "Recall Score : 0.8115942028985508 \n",
      "F1 Score: 0.767123287671233\n"
     ]
    }
   ],
   "source": [
    "y_pred = prediction_by_threshold(X_val, m)\n",
    "\n",
    "print('Accuracy Score :',accuracy_score(y_val, y_pred),\n",
    "      '\\nPrecision Score :', precision_score(y_val, y_pred),\n",
    "      '\\nRecall Score :', recall_score(y_val, y_pred),\n",
    "      '\\nF1 Score:', f1_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At -0.31 threshold, we are getting precision = recall\n",
    "\n",
    "Let's try our luck on test set of the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"test.csv\")\n",
    "X_test['Family'] = X_test['SibSp']+X_test['Parch']+1\n",
    "X_test1 = preprocess_pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf_y_pred = prediction_by_threshold(X_test1, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'PassengerId': X_test.PassengerId, 'Survived': log_clf_y_pred})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('log_clf_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we are getting around 75.1% on the Kaggle test set, though we are getting 81% on our validation set. We may have to get more training data to perform better on test set which is not possible.\n",
    "\n",
    "Even setting a classification threshold we are doing not so great on the test set.\n",
    "\n",
    "Let's plot ROC Curve and explore some more on our error analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--') # dashed diagonal\n",
    "    plt.axis([0, 1, 0, 1])                                    \n",
    "    plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) \n",
    "    plt.ylabel('True Positive Rate (Recall)', fontsize=16)  \n",
    "    plt.grid(True)                                          \n",
    "\n",
    "plt.figure(figsize=(8, 6))                                    \n",
    "plot_roc_curve(fpr, tpr)                                              \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good classifier stays as far away from that line as possible (toward the top-left corner), which is obviously our model is not achieving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8466962792530811"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_train, y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf = RandomForestClassifier()\n",
    "\n",
    "forest_clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8156424581005587"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_y_pred = forest_clf.predict(X_val)\n",
    "\n",
    "accuracy_score(y_val, forest_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "81.56% It's better than our previous model. But would we get this on our test test, that's the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis for Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[463,  86],\n",
       "       [100, 242]], dtype=int64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = cross_val_predict(forest_clf, X_train, y_train, cv=3)\n",
    "\n",
    "conf_mt = confusion_matrix(y_train, y_train_pred)\n",
    "conf_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(conf_mt, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train, cv=3,\n",
    "                                    method=\"predict_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_forest = y_probas_forest[:, 1] # score = proba of positive class\n",
    "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train,y_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "recall_for_forest = tpr_forest[np.argmax(fpr_forest >= fpr_90)]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, \"b:\", linewidth=2, label=\"Logistic Regression\")\n",
    "plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"lower right\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8418762449536106"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, y_scores_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area under the curve of Random Forest Classifier is better than Logistic Regression but just a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7378048780487805"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7076023391812866"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7223880597014926"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the precision and recall are pretty close, and still we are doing just a little better than Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('test.csv')\n",
    "X_test['Family'] = X_test['SibSp'] + X_test['Parch'] + 1\n",
    "X_test1 = preprocess_pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38623105, -0.49741333, -0.5534426 , ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 1.37137004, -0.51227801,  0.10564289, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 2.55353683, -0.46410047, -0.5534426 , ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.70147553, -0.50779638, -0.5534426 , ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.20485235, -0.49345515, -0.5534426 , ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.20485235, -0.23695704,  0.76472838, ...,  1.        ,\n",
       "         1.        ,  1.        ]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_y_test_pred = forest_clf.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'PassengerId': X_test.PassengerId, 'Survived': forest_y_test_pred})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split this data set into train and test first as in previous scenario, I was getting 84% cross_val_score here but only 77% on test set after Kaggle submission. So, I will try to tune the each model's parameter using Grid Search now and see if I can do any better.\n",
    "\n",
    "If you have any ideas to better my model, do let me know in the comments and please upvote my work, thanks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
